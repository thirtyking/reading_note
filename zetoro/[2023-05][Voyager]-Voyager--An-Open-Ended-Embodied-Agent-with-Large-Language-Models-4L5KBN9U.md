---
tags: []
parent: '[Voyager] Voyager: An Open-Ended Embodied Agent with Large Language Models'
collections:
    - 自进化
$version: 2258
$libraryID: 1
$itemKey: 4L5KBN9U

---
\[2023-05]\[Voyager] Voyager: An Open-Ended Embodied Agent with Large Language Models

# \[Voyager] Voyager: An Open-Ended Embodied Agent with Large Language Models

## 概述

你好！很高兴能为你解读这篇在 AI 圈非常有影响力的论文《Voyager: An Open-Ended Embodied Agent with Large Language Models》。

你可以把 **Voyager（航行者）** 想象成一个被丢进《我的世界》（Minecraft）游戏里的“数字小人”。以往的 AI 玩游戏可能需要人类手把手教，或者通过几百万次的失败来摸索，但 Voyager 却能像聪明的人类玩家一样，自己给自己定目标，自己写代码学习技能，并且不断积累经验。

下面我为你详细拆解这篇论文：

***

### 1. 本论文要解决什么问题？为什么重要？

**要解决的问题：** 如何让 AI 成为一个\*\*“终身学习者”\*\*（Lifelong Learner）。具体来说，就是让它在一个开放、复杂且没有固定终点的环境（如《我的世界》）中，不需要人类干预，就能自主地探索、学习新技能并完成极其复杂的任务。

**为什么重要：** 现在的 AI 大多是“一招鲜”，学会了下棋就只会下棋。但真正的智能（通用人工智能，AGI）应该像人一样，能够在一个未知的环境中生存，发现新问题，并利用学到的旧知识去解决新麻烦。如果 AI 能在《我的世界》里自主生存得很好，那它未来就有可能在现实世界的复杂场景（比如家政机器人、火星探索）中大显身手。

***

### 2. 难点在哪里？之前的方案为什么不行？

**难点：**

*   **规划时间极长：** 从砍树到合成一把钻石镐，中间涉及成千上万个动作，AI 很容易“迷路”。
*   **探索漫无目的：** 游戏世界太大，AI 如果只是随机乱走，可能玩上一万年也找不到金矿。
*   **记忆缺失：** 很多 AI 学会了一个动作后，下次遇到同样的问题还要重新学，没法把经验“存”起来。

**之前的方案：**

*   **强化学习（Reinforcement Learning）：** 通过“试错”来学习。**缺点：** 学习效率极低。在复杂任务中，AI 可能因为一直拿不到奖励（比如没挖到钻石）而产生挫败感，最后原地打转。
*   **早期的 LLM 智能体（如 ReAct）：** 直接让大模型下指令。**缺点：** 大模型容易“健忘”。它可能这一秒知道怎么砍树，下一秒就忘了，而且它输出的是简单的动作指令，无法处理非常复杂、精细的操作。

***

### 3. Voyager 提出了什么解决方案？

Voyager 决定不直接控制角色的“手脚”（即不直接发送按键指令），而是把 **LLM（大语言模型，如 GPT-4）** 当成“大脑”，让大脑去\*\*写代码（Javascript）\*\*来控制角色。

**核心逻辑：**

1.  **自己定任务：** 大脑根据现状，给自己写个“待办清单”。
2.  **写代码实现：** 针对清单上的任务，大脑写一段代码去尝试完成。
3.  **存入技能库：** 如果代码运行成功，就把这段代码存进“技能书”里。
4.  **遇到困难查书：** 下次遇到类似或更难的任务，先从“技能书”里找找有没有能用的代码，或者把旧代码组合成新代码。

***

### 4. 方案的核心创新点（三大支柱）

这是 Voyager 最精彩的部分，它由三个关键组件构成：

1.  **自动课程表（Automatic Curriculum）：**

    *   *解释：* 它不是瞎逛，而是会根据自己现在的装备（比如只有木剑）和环境（比如附近有猪），自主决定下一个目标（比如去打肉）。它会尝试挑战比现在难一点点的任务，保持“进取心”。

2.  **技能库（Skill Library）：**

    *   *解释：* 这是它的“宝典”。所有成功运行的代码（比如一段名为 `mineWood()` 的代码）都会被存储起来。这意味着它不需要重复学习，能力是指数级叠加的。**这是 Voyager 远超之前方案的关键。**

3.  **迭代提示机制（Iterative Prompting Mechanism）：**

    *   *解释：* AI 写代码也会出错。Voyager 运行代码后，如果报错了，或者发现目标没达成，它会把**报错信息**、**当前截图的文字描述**反馈给 LLM，让它“反思”并修改代码，直到成功为止。这就像程序员边写代码边 Debug（排错）。

***

### 5. 局限性与劣势

虽然 Voyager 很强，但它也有短板：

*   **成本高昂：** 它极其依赖像 GPT-4 这样的大模型 API，每走一步都要花钱，且响应速度慢（需要等待模型生成代码）。
*   **缺乏视觉直觉：** 目前它主要靠文字描述来感知世界（比如“你左边有一头猪”），而不是像人类一样直接看像素画面。这导致它在一些需要极强视觉反应的任务（比如激烈战斗）中表现不如经过专门训练的强化学习模型。
*   **由于代码局限：** 如果某些精细动作很难用代码表达，或者代码库里没有相关的基础函数，它就会卡住。

***

### 6. 关键架构图解读

在论文中，你会看到一张核心流程图（通常包含三个循环）：

*   **左侧：自动课程（Automatic Curriculum）**

    *   它展示了 LLM 如何观察环境状态，从备选目标中挑选一个最合适的，这就像是一个“导航员”。

*   **中间：技能库（Skill Library）**

    *   你会看到很多代码片段（Code Snippets）。这部分展示了它是如何通过检索（Retrieval）找到旧知识，并将新知识存入（Store）的过程。它把“知识”变成了“可执行的程序”。

*   **右侧：迭代改进（Iterative Prompting）**

    *   这显示了一个循环：写代码 -> 运行环境 -> 获取报错/反馈 -> 重新写代码。这辅助理解了为什么它能自主学会复杂的动作，因为它具备\*\*“自我修正”\*\*的能力。

**总结：** Voyager 的成功告诉我们，AI 不一定非要通过死记硬背（参数训练）来学习，通过\*\*“高阶思维（LLM）+ 工具箱（代码库）+ 持续尝试（迭代反馈）”\*\*，AI 可以在开放世界中展现出惊人的进化能力。

## 思考一

Voyager 会把出错和反思的过程记录下来，并在后续利用这些知识对大模型进行训练吗？

***

这是一个非常深入的问题，触及了 **Voyager** 与传统 AI 训练方式的核心区别。

简单直接的回答是：**Voyager 不会对大模型（LLM）本身进行“训练”（即不修改模型的参数/权重），它是通过“外部进化”的方式来积累知识的。**

为了让你理解得更透彻，我们可以从以下几个维度来拆解：

### 1. 它是“改进代码”，而不是“训练大脑”

在机器学习中，“训练”通常指的是**微调（Fine-tuning）**，也就是改变模型内部的数值，让它变得更聪明。但 Voyager 认为这样做太慢且太贵了。

*   **Voyager 的做法：** 它的“大脑”（GPT-4）是保持不变的。当它出错并反思时，这个过程发生在\*\*对话框（Prompt）\*\*里。

*   **例子：** 就像你请了一位顶级教授帮你写程序。

    *   教授第一次写错了，程序报错。

    *   你把报错信息发给教授，教授看了一眼说：“噢，我明白了，这里少了个括号。”

    *   教授重新写了一份对的给你。

    *   **结果：** 教授本人并没有通过这个过程去参加考试进修（训练），但你手里得到了一份**正确的代码**。

### 2. 反思过程去哪了？（迭代提示机制）

你提到的“出错和反思的过程”，在论文中被称为 **Iterative Prompting（迭代提示）**。

*   这个过程是**临时**的。它只为了解决眼下的这个特定任务（比如：怎么挖到铁矿）。

*   一旦代码调试成功，Voyager 会把这份**最终成功的代码**存入“技能库”。

*   **而那些失败的尝试、报错信息、中间的反思过程，在任务完成后就会被“丢弃”，不会存入技能库，也不会用来喂给模型做训练。**

### 3. 它如何利用积累的知识？（技能库 vs 模型参数）

虽然它不训练模型，但它通过 **Skill Library（技能库）** 实现了类似“学习”的效果：

*   **传统 AI：** 把知识记在脑子里（修改参数）。

*   **Voyager：** 把知识记在笔记本上（技能库）。

*   **后续利用：** 当下次遇到新任务时，Voyager 会在笔记本里搜索：“我以前有没有写过类似的代码？” 如果有，它就把那段成功的代码直接复制出来，作为参考。

*   **这就是为什么它能越玩越好：** 并不是因为 GPT-4 变聪明了，而是因为它的“工具箱”里的现成工具（成功代码）越来越丰富了。

### 4. 为什么不选择“训练”大模型？

作为资深研究员，我可以告诉你论文作者背后的考量：

1.  **成本与速度：** 微调一个像 GPT-4 这样的大模型非常昂贵，且耗时极长。而写一段代码、存进数据库只需要几毫秒。

2.  **准确性：** 代码是“确定性”的。一旦一段 `mineDiamond()` 的代码写对了，它以后永远都是对的。但如果通过训练来让模型学习，模型还是可能会有“幻觉”，偶尔把代码写错。

3.  **可迁移性：** 这个技能库（代码库）是可以直接复制给另一个 AI 用的，甚至人类程序员也能看懂并使用。如果是训练出来的模型权重，那就是一个谁也看不懂的“黑盒”。

### 总结

Voyager 并不是在\*\*“进化大脑”**，而是在**“编写一本越来越厚的生存指南”\*\*。

*   **出错和反思：** 是为了写出“指南”中正确的一页。

*   **知识积累：** 体现在那本“指南”（技能库）越来越完善，而不是大模型本身发生了变化。

这种思路被称为 **In-Context Learning（语境学习）** 和 **RAG（检索增强生成）** 的结合，是目前 AI 智能体领域最主流、最高效的发展方向。
