---
tags: []
parent: '[Few-Shot] Language Models are Few-Shot Learners'
collections:
    - 学习范式
$version: 2205
$libraryID: 1
$itemKey: HGJ5AFJL

---
\[2020-05]\[Few-Shot] Language Models are Few-Shot Learners

# \[Few-shot] Language Models are Few-Shot Learners

你好！很高兴能带你解读这篇划时代的论文：《Language Models are Few-Shot Learners》（语言模型是少样本学习者），也就是大家都知道的 **GPT-3**。

既然你对机器学习有一些基础，我们就不纠结于繁琐的数学公式，而是把重点放在\*\*“思维方式的转变”\*\*上。这篇论文之所以经典，是因为它彻底改变了我们通过 AI 解决问题的方式。

我们开始吧。

***

### 1. 本论文要解决什么问题？为什么这个问题很重要？

**核心问题：如何让 AI 像人类一样，不再需要大量的专门训练，就能学会新任务？**

在 GPT-3 之前，如果你想要一个能翻译的 AI，你需要准备几万句翻译数据来训练它；如果你想要一个能做算术的 AI，又要准备几万道算术题。

**重要性：** 人类具有一种极强的能力，叫做\*\*“通用性”**和**“举一反三”**。 比如我教你一个新的造句游戏，我只需要给你演示一两个例子（Few-Shot），你马上就懂了，不需要做几万道题才能学会。 如果 AI 始终需要针对每个任务都重新训练一遍，那它永远只是个“偏科的工具”，而不是通用的智能。GPT-3 想要解决的，就是让模型摆脱对大量特定任务数据的依赖，实现真正的**通用语言理解\*\*。

***

### 2. 解决这个问题的难点在哪里？之前是怎么做的？

**之前的解决方案：Pre-training + Fine-tuning（预训练 + 微调）**

这是 BERT 时代的标准范式：

1.  **预训练（Pre-training）：** 先让模型读大量的书（通用数据），学个大概。
2.  **微调（Fine-tuning）：** 再给模型看某个特定任务（比如情感分类）的数据，**通过梯度下降（Gradient Descent）修改模型的参数**，让它变成这个任务的专家。

**这种方案的局限性（为什么不能很好解决）：**

1.  **数据昂贵：** 每一个新任务都需要大量的标注数据（Labelled Data），这非常花钱花时间。
2.  **灾难性遗忘：** 模型一旦为了“翻译”任务修改了参数，它可能就忘了怎么“写诗”了。
3.  **不像人类：** 人类不需要为了学个新游戏就去修改大脑的神经元连接（修改参数），我们只是通过“听指令”和“看例子”来适应。之前的模型必须修改参数才能适应新任务，这显得很笨重。

***

### 3. 本论文提出了何种解决方案？为什么能行？

**解决方案：In-Context Learning（上下文学习）+ 暴力扩容（Scale Up）**

GPT-3 提出了一个惊人的假设：我们根本不需要“微调”（即不修改模型参数）。我们只需要把任务描述和几个例子写在输入里（Prompt），模型就能自己“领悟”你要干什么，并输出结果。

**具体做法：**

*   **不改参数：** 模型训练好后，参数就锁死了。

*   **给提示（Prompting）：**

    *   如果你想让它翻译，你就输入：“请把英语翻译成法语：Hello -> Bonjour, Good morning ->”
    *   模型会根据前面的规律，自动补全：“Bonjour”。

**为什么能行？（Why it works）** 这里就是 GPT-3 最“玄学”也最震撼的地方：**大力出奇迹**。 研究人员发现，当语言模型的**参数量（Parameters）大到一定程度（GPT-3 做到了 1750 亿参数，是 GPT-2 的 100 倍），并且在足够海量的数据上训练后，模型会出现一种“涌现能力（Emergent Ability）”**。 它在阅读海量文本的过程中，已经隐式地学会了各种任务的模式。当你给它几个例子时，它并不是在“学习”，而是在它庞大的知识库中**检索**并**匹配**这种模式。

***

### 4. 方案的核心创新点在哪里？

1.  **定义了 Few-Shot 的新范式：** 证明了在 **不进行任何梯度更新（No Gradient Updates）** 的情况下，仅凭输入里的几个例子，AI 就能达到甚至超过那些经过专门微调的模型的表现。
2.  **规模效应的验证：** 它向世界证明了，Transformer 结构的语言模型，只要堆得足够大、数据足够多，量变会引起质变。这直接引发了后来两年的“大模型军备竞赛”。
3.  **通用的接口：** 以前做翻译用翻译模型，做问答用问答模型。GPT-3 告诉我们，所有 NLP（自然语言处理）任务本质上都是 **“文本生成”** 问题，可以用同一个模型解决。

***

### 5. 关键架构图解读

论文中有一张非常核心的图，对比了 **Traditional Fine-tuning（传统微调）** 和 **Few-Shot（少样本）** 的区别。这能帮你直观理解它的方法论。

#### **图的内容描述：**

这张图通常分为上下或左右两部分对比：

*   **部分 A（Fine-Tuning）：**

    *   画着一个模型，有一个箭头指向它，标着“Gradient Update”（梯度更新）。
    *   意味着：为了做这道题，我需要打开模子，修改里面的数学参数。

*   **部分 B（In-Context Learning - Zero/One/Few-Shot）：**

    *   画着同一个模型，但**没有**“Gradient Update”的箭头。
    *   **Zero-shot（零样本）：** 输入只有一句指令：“Translate English to French: cheese =>”。
    *   **One-shot（单样本）：** 输入有一句指令 + 一个例子：“Translate English to French: sea otter => loutre de mer, cheese =>”。
    *   **Few-shot（少样本）：** 输入有一句指令 + 多个例子（10-100个）：列出一堆单词对照，最后才是你要问的词。

#### **如何辅助理解：**

这张图点明了 GPT-3 的灵魂：**将“学习”的过程，从“修改模型内部参数”转移到了“设计模型输入文本”上。**

*   以前我们是“改写大脑”（Fine-tuning）；
*   现在我们是“给大脑看说明书”（In-context learning）。
*   Few-Shot 的本质就是利用 Transformer 强大的**注意力机制（Attention Mechanism）**，让模型去“注意”你给的那几个例子，从而瞬间模仿出你想要的输出格式。

***

### 总结一下给学生的话：

GPT-3 这篇论文其实就讲了一个道理：**当模型足够大、书读得足够多时，它就不再是一个只会死记硬背的机器，而是一个能听懂人话、能通过看例子瞬间适应新任务的通用智能体。** 它不仅省去了针对特定任务训练的麻烦，更重要的是，它让我们看到了通往 AGI（通用人工智能）的一条清晰路径——把模型做大。
