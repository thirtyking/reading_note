---
tags: []
parent: '[NEFTune] NEFTune: Noisy Embeddings Improve Instruction Finetuning'
collections:
    - SFT策略
$version: 2235
$libraryID: 1
$itemKey: JAMD6IXD

---
\[2023-10]\[NEFTune] NEFTune: Noisy Embeddings Improve Instruction Finetuning

# \[NEFTune] NEFTune: Noisy Embeddings Improve Instruction Finetuning

## 概述

你好！很高兴你对这篇论文感兴趣。来，坐下，我们把复杂的公式先放一边，我用最通俗的语言带你把 **NEFTune** 这篇论文的核心逻辑理顺。

这篇文章的全称是《NEFTune: Noisy Embeddings Improve Instruction Finetuning》，也就是“在指令微调中加入噪声嵌入能提升效果”。

咱们按你的要求，一点点拆解。

***

### 1. 这论文要解决什么问题？为什么它很重要？

**核心问题：** 解决大模型在“指令微调”（Instruction Finetuning）阶段的 **过拟合（Overfitting）** 问题。

**通俗解释：** 想象你在教一个学生（大模型）考试。

*   **预训练（Pre-training）** 就像是让他读了全世界的书，他知识很渊博，但不懂怎么规范答题。

*   **指令微调** 就是最后发给他几万道“模拟题”和“标准答案”，让他学会：“哦，原来用户问这个问题时，我应该用这种格式、这种语气来回答。”

**问题在于：** 模拟题的数量通常很少（比如只有几万条），而且很多是 GPT-4 生成的，风格很单一。学生（模型）很容易“死记硬背”。他可能学会了“标准答案”的说话套路，但思维变窄了，稍微换个问法或者面对新领域，他就只会套模版，甚至复读训练集里的废话。

**重要性：** 如果解决不好这个问题，微调出来的模型虽然看起来像是在回答问题，但实际上丧失了预训练阶段获得的很多通用能力，变得“呆板”。我们希望模型既懂规矩，又能保持头脑灵活。

***

### 2. 解决这个问题的难点在哪里？之前的方案为什么不够好？

**难点：** 数据太少，模型太大。 大模型参数动辄几十亿，而微调数据往往只有几万条。这就像让一个天才去死磕一本只有 10 页的练习册，他肯定会把练习册里的每一个标点符号都背下来，而不是去理解背后的逻辑。

**之前的解决方案及缺陷：**

1.  **增加数据：** 最直接，但最贵。高质量的指令数据（比如让真人去写）非常昂贵。

2.  **标准正则化手段（如 Dropout）：**

    *   *解释：* Dropout 是传统深度学习常用的防过拟合手段，原理是在训练时随机“关掉”一些神经元。

    *   *缺陷：* 在大语言模型（LLM）中，大家发现 Dropout 往往效果不好，甚至会破坏 Transformer 结构的训练稳定性，导致模型收敛变慢。所以现在的 LLM 训练几乎很少用 Dropout。

3.  **权重衰减（Weight Decay）：** 这是一个标准操作，但它是一种很温和的全局约束，对于指令微调这种特定场景下的“风格过拟合”，效果有限。

**总结：** 以前的方法要么太贵（加数据），要么在 LLM 上水土不服（Dropout）。

***

### 3. 本论文提出了什么解决方案？为什么能解决？

**核心方案：NEFTune (Noisy Embedding Full Tune)**

**一句话概括：** 在模型训练时，给输入的文字向量（Embedding）**加一点随机噪声**。

**具体怎么做？**

1.  正常情况下，模型把单词（Token）转换成一串数字（向量），比如“猫”变成了 `[0.1, 0.5, ...]`。

2.  NEFTune 说：“别急着往后传，给这串数字加上一个随机生成的噪声。”

3.  于是“猫”变成了 `[0.12, 0.48, ...]`。

4.  然后带着这个“有点脏”的数据去训练模型。

5.  **注意：** 只有在**训练**时加噪声，**测试/使用**时是不加的。

**为什么这能解决问题？（原理通俗化）** 这就像在给学生做模拟题时，我不让你看清晰的打印版，而是给你看**字迹稍微有点潦草**的手写版，甚至每次给你看的时候，字迹潦草的方式都不一样。

*   **防止死记硬背：** 因为每次看到的输入向量都有一点细微的差别，模型就不能死记硬背具体的“坐标点”。

*   **强迫抓重点：** 模型被迫去忽略那些细微的干扰（噪声），去抓取更本质的语义特征。它必须学会：“不管这个向量偏左一点还是偏右一点，它都是‘猫’。”

*   **结果：** 这样训练出来的模型，不再局限于训练集那狭窄的分布，由于见过了“各种带噪声的版本”，它的适应能力（鲁棒性）更强了。

***

### 4. 方案的核心创新点在哪里？

这个方案最牛的地方在于：**大道至简**。

1.  **极其简单：** 相比于那些设计复杂损失函数、引入强化学习的方法，NEFTune 只需要在代码里加 **3 行** 就能实现。

2.  **反直觉的有效：** 以前大家觉得 Embedding（嵌入层）是模型最基础的语义入口，加噪声可能会把含义搞乱。但这篇论文证明了，只要控制好噪声的大小，这反而是一种极佳的正则化手段。

3.  **效果显著：** 在 AlpacaEval（一个评估模型聊天能力的榜单）上，使用了 NEFTune 的 LLaMA-2-7B 模型，效果竟然比不用的版本提升了大幅度（从 29.8% 提升到 64.7%），甚至超过了一些更大的模型。

***

### 5. 局限性与劣势

虽然 NEFTune 效果好，但作为研究员，我要提醒你注意它的局限性：

1.  **对参数敏感：** 噪声加多少（噪声的缩放系数  $\alpha$ ）是个玄学。加少了没用，加多了模型就“疯了”，连话都说不通顺。不同大小的模型、不同的数据集，最佳的噪声系数可能不一样，需要你去调参。

2.  **可能带来“幻觉”或废话：**

    *   论文中观察到，使用了 NEFTune 的模型，回答往往会变得**更长**。

    *   在聊天场景下，回答长显得很详细，得分高。但在要求精确简练的场景下（比如代码生成、数学题），这种“罗嗦”可能不是好事。

    *   有研究质疑，它分数的提升部分原因是因为模型学会了“多说话”，而不完全是逻辑变强了。

3.  **并不增加知识：** 它只是让模型把已有的知识用得更好，并不能让模型知道它不知道的事。如果训练数据本身质量很差（全是错误答案），加了噪声也没救。

4.  **与之前方案相比的劣势：** 相比于“增加高质量数据”这种王道方法，NEFTune 是一种“取巧”的优化。如果你的数据量足够大（比如你有几百万条高质量数据），NEFTune 带来的边际收益可能会大大降低，甚至不如不做。

### 总结给学生：

**NEFTune 就是在模型训练时，往输入数据里撒了一把“沙子”（随机噪声）。这迫使模型不能偷懒死记硬背，必须全神贯注地理解核心语义。这是一个用极低成本换取显著性能提升的典型 Trick。**
