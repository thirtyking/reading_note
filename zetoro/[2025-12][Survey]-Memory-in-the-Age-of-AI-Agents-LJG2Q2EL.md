---
tags: []
parent: '[Agent Memory] Memory in the Age of AI Agents'
collections:
    - '0. 综述'
$version: 2258
$libraryID: 1
$itemKey: LJG2Q2EL

---
\[2025-12]\[Survey] Memory in the Age of AI Agents

# \[Survey] Memory in the Age of AI Agents

## 概述

你好！很高兴能为你解读这篇具有里程碑意义的综述论文——《AI Agent 时代的记忆：形式、功能与演化》（Memory in the Age of AI Agents: A Survey）。

作为一名 AI 研究员，我深知对于刚接触机器学习的同学来说，LLM（大语言模型）虽然强大，但总觉得它像个“只有秒记，没有长记性”的聪明人。这篇文章正好系统性地梳理了我们是如何给 AI 赋予“记忆力”的。

***

### 1. 这个领域是为了解决什么问题而诞生的？

简单来说，是为了解决大模型的\*\*“断片儿”问题（Statelessness，无状态性）\*\*。

*   **瞬时性：** 原生的 LLM 像是一个博学但患有“短期记忆丧失症”的专家。你问它一个问题，它根据脑子里的知识（训练数据）回答你；但一旦对话结束或超出了一定的字数限制（Context Window，上下文窗口），它就会把刚才聊过的内容忘得干干净净。

*   **无法进化：** 如果没有记忆系统，Agent（智能体）就无法从失败中吸取教训，也没法记住你的个人偏好。它永远停留在出厂状态，无法实现真正的**持续学习（Continual Learning）**。

*   **成本与容量矛盾：** 虽然现在的模型窗口越来越长，但把所有历史记录都塞进去会导致计算非常昂贵且效率低下。

**领域目标：** 让 AI Agent 拥有像人一样的存储、回忆和自我更新能力，使其能够处理长期的、复杂的任务，并表现得更有个性、更懂用户。

***

### 2. 如何评价领域中的方法对问题解决的好不好？

评价一个记忆系统“行不行”，主要看这几个维度：

1.  **准确性与召回率（Recall）：** 当需要某段信息时，Agent 能不能从海量记忆中精准地把它找出来？

2.  **一致性（Consistency）：** Agent 表现出来的性格和掌握的事实是否前后矛盾？（比如：刚才说自己姓王，现在又说姓李）。

3.  **泛化能力（Generalization）：** Agent 能不能从过去的经验中总结出规律，用到没见过的新场景里？（不仅仅是复读，而是举一反三）。

4.  **遗忘管理（Forgetting/Pruning）：** 记忆不是越多越好。系统能不能自动删掉没用的垃圾信息，腾出空间给重要的事？

5.  **效率（Efficiency）：** 读取记忆的速度快不快？占用的内存和计算资源多不多？

***

### 3. 这个领域时间轴上的重要节点和相关论文

这个领域的发展非常迅速，大致可以分为三个阶段：

*   **第一阶段：朴素上下文阶段（2022年及以前）**

    *   **代表作：** *ReAct (Yao et al., 2022)*。它提出了让模型一边思考一边行动。当时的记忆就是简单的对话历史堆叠。

*   **第二阶段：外部工具与 RAG 介入阶段（2023年）**

    *   **重要节点：** *Generative Agents (Park et al., 2023)*（著名的斯坦福“虚拟小镇”实验）。它证明了通过“感知-存储-反思”架构，AI 可以拥有类似人类的长期生活记忆。

    *   **重要节点：** *MemGPT (Packer et al., 2023)*。借鉴了操作系统的虚拟内存管理思想，让 Agent 能够处理无限长的对话。

*   **第三阶段：深度内化与自我演化阶段（2024-2025年）**

    *   **代表作：** *MemoryLLM (Wang et al., 2024)*。开始尝试直接修改模型内部状态来存储记忆。

    *   **代表作：** *Memory-R1 (Yan et al., 2025)*。通过强化学习（RL）让 AI 自己学会什么时候该记、什么时候该忘。

***

### 4. 这个领域的研究分类及典型代表

本文提出了一套非常清晰的“三位一体”分类法（Forms-Functions-Dynamics）：

#### A. 按“存储形式”（Forms）分类：

1.  **Token 级记忆（Token-level）：** 把记忆存成文本块。

    *   *典型代表：* **MemGPT** (虚拟内存管理)、**GraphRAG** (图结构记忆)。

2.  **参数记忆（Parametric）：** 直接通过微调或模型编辑，把知识刷进模型的“神经网络权重”里。

    *   *典型代表：* **ROME** (直接修改模型参数中的事实知识)。

3.  **隐空间记忆（Latent）：** 把记忆存成模型能懂的向量（Embedding）或内部状态（KV Cache）。

    *   *典型代表：* **Gist (Mu et al., 2023)** (把长文本压缩成几个关键向量)。

#### B. 按“功能用途”（Functions）分类：

1.  **事实记忆（Factual）：** 记住关于用户或环境的硬知识（如：用户喜欢吃苹果）。

    *   *典型代表：* **MemoryBank**。

2.  **经验记忆（Experiential）：** 记住解决问题的套路（如：上次写代码报错是因为少了个分号）。

    *   *典型代表：* **Reflexion** (通过自我反思积累经验)。

3.  **工作记忆（Working）：** 当前任务正在用的临时草稿本。

    *   *典型代表：* **Context-Folding** (压缩当前对话)。

#### C. 按“演化动态”（Dynamics）分类：

1.  **形成（Formation）：** 如何把经历转化为笔记？

    *   *代表作：《MemGPT》(2023)，《GraphRAG》(2025)，《AWM (Agent Workflow Memory)》(2024)*

2.  **演化（Evolution）：** 如何更新和修剪笔记本？

    *   *代表作：《MemoryBank》(2024)，《D-SMART》(2025)，《Mem-α》(2025)*

3.  **检索（Retrieval）：** 关键时刻如何想起它？

    *   *代表作：《HyDE》(2023)，《Self-RAG》(2024)，《PRIME》(2025)*

***

### 5. 当前的研究热点是什么？

1.  **RL-driven Memory Control（强化学习驱动的记忆控制）：**不要人工写死规则，而是让模型在玩的过程中发现：噢，记住这段话能帮我拿高分，那我就记下它。

    *   *代表作：* **Memory-R1**。

2.  **Memory Generation（记忆生成/内化）：**不再是简单的“搜搜看”，而是 Agent 晚上“睡觉”时，把白天的琐碎经历总结成深刻的道理。

    *   *代表作：* **ComoRAG**。

3.  **Multimodal Memory（多模态记忆）：**Agent 不仅要记住聊过什么，还要记住见过什么（图片）、听过什么（音频）。

    *   *代表作：* **MemoryVLA**。

4.  **Trustworthy Memory（可信记忆）：**涉及隐私保护（用户让你删掉记忆时，你必须彻底忘掉）和幻觉消除。

    *   *代表作：* **RAMDocs**。

***

### 6. Top 20 核心论文列表（按影响力/代表性排序）

*注：由于该综述发布于 2025 年底，部分 2025 年的论文引用数属于“潜力股”预测。*

| 论文标题                  | 年份   | 估计引用数 | 分类标签         | 核心贡献                                   |
| :-------------------- | :--- | :---- | :----------- | :------------------------------------- |
| **Generative Agents** | 2023 | 2500+ | 事实记忆, Token级 | 提出了“反思”机制，开创了社会化 Agent 记忆模拟的先河。        |
| **ReAct**             | 2022 | 3000+ | 工作记忆, Token级 | 将推理(Reason)与行动(Act)结合，奠定了 Agent 记忆的基础。 |
| **MemGPT**            | 2023 | 1200+ | 工作记忆, Token级 | 引入操作系统内存管理概念，实现无限长上下文。                 |
| **Reflexion**         | 2023 | 800+  | 经验记忆, Token级 | 提出通过自我反思将错误转化为经验记忆。                    |
| **ROME**              | 2022 | 1000+ | 参数记忆         | 实现了对大模型内部特定事实的精准定位和修改。                 |
| **Voyager**           | 2023 | 700+  | 经验记忆, Token级 | 在我的世界里通过积累“技能代码库”实现持续进化。               |
| **MemoryLLM**         | 2024 | 400+  | 隐空间记忆        | 通过特殊 Token 让模型具备自更新的长短期记忆。             |
| **GraphRAG**          | 2024 | 600+  | 事实记忆, Token级 | 结合知识图谱提升了复杂关系记忆的检索深度。                  |
| **Memory-R1**         | 2025 | 300+  | 演化动态, RL驱动   | 首个大规模利用强化学习自主训练记忆管理策略的方法。              |
| **Gist Tokens**       | 2023 | 500+  | 隐空间记忆        | 将长提示词压缩成极短的“要点”向量。                     |
| **Self-RAG**          | 2023 | 800+  | 检索动态         | 让模型学会自我判断何时需要检索记忆。                     |
| **MemoryBank**        | 2024 | 300+  | 事实记忆         | 模拟人类遗忘曲线（Ebbinghaus）进行记忆清理。            |
| **HyDE**              | 2023 | 900+  | 检索动态         | 提出“假设性文档嵌入”，极大地提高了模糊记忆的搜寻成功率。          |
| **TITANS**            | 2025 | 200+  | 隐空间记忆        | 利用神经网络权重作为高速流式记忆层。                     |
| **ExpeL**             | 2024 | 250+  | 经验记忆         | 从跨任务的成功和失败案例中自主学习操作指南。                 |
| **Context-Folding**   | 2025 | 150+  | 工作记忆         | 动态折叠不重要的对话，保持工作记忆的紧凑性。                 |
| **AgentFold**         | 2025 | 100+  | 工作记忆         | 针对长程任务的层次化工作记忆管理。                      |
| **MemoryVLA**         | 2025 | 120+  | 多模态记忆        | 为视觉-语言-行动模型配备了跨模态的感知存储。                |
| **Zep**               | 2024 | 200+  | 框架/事实记忆      | 提供了工业级的 Agent 长期记忆管理基础设施。              |
| **Mem0**              | 2025 | 180+  | 框架/事实记忆      | 实现了高度个性化、可自主进化的记忆管理层。                  |


希望这份解读能帮你建立起 AI Agent 记忆领域的全局观！如果有哪个具体的技术细节想深挖，随时告诉我。
