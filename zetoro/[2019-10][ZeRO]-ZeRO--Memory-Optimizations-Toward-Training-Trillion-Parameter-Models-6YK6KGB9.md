---
tags: []
parent: '[ZeRO] ZeRO: Memory Optimizations Toward Training Trillion Parameter Models'
collections:
    - 显存优化
$version: 2256
$libraryID: 1
$itemKey: 6YK6KGB9

---
\[2019-10]\[ZeRO] ZeRO: Memory Optimizations Toward Training Trillion Parameter Models

# \[ZeRO] ZeRO: Memory Optimizations Toward Training Trillion Parameter Models

## 概述

你好！很高兴为你解读这篇非常有影响力的论文：**ZeRO: Memory Optimizations Toward Training Trillion Parameter Models**。

这篇论文是微软 DeepSpeed 团队在 2019 年提出的，它的出现可以说是大模型（LLM）时代的“助推器”。如果没有 ZeRO，我们在有限的显卡上训练千亿甚至万亿参数的模型将会极其困难。

下面我尽量用通俗的语言，带你拆解这篇论文的核心逻辑。

***

### 1. 本论文要解决什么问题？为什么这个问题很重要？

**核心问题：显存不够用（Memory Wall）。**

随着 AI 的发展，模型变得越来越大（从 BERT 的几亿参数到 GPT-3 的 1750 亿参数）。“参数”越多，模型越聪明，但它们占用的内存（显存）也极其恐怖。

**为什么重要？** 现在的显卡（GPU）虽然算力提升很快，但显存大小（比如 32GB、80GB）增长得很慢。

*   **现状：** 如果你想训练一个大模型，你会发现显卡显存瞬间爆满（OOM, Out of Memory），导致训练无法启动。

*   **目标：** 这篇论文就是为了打破这个“内存墙”，让研究人员能在现有的硬件条件下，训练出比以前大几十倍甚至上百倍的模型（迈向万亿参数）。

***

### 2. 解决这个问题的难点在哪里？之前的方案有什么缺陷？

**难点：训练模型时，究竟是谁吃掉了显存？**

很多学生以为显存里只存了**模型参数（Model Parameters，即权重 weights）**。其实不然，训练大模型时，显存里主要存了三样东西：

1.  **模型参数（Parameters）：** 模型本身的权重。

2.  **梯度（Gradients）：** 反向传播时计算出来的更新方向。

3.  **优化器状态（Optimizer States）：** 这是“隐形杀手”。比如最常用的 Adam 优化器，为了保持训练稳定，需要为每个参数额外存储“动量”和“方差”。**这部分占用的显存通常是模型参数本身的 3-4 倍！**

**之前的解决方案及缺陷：**

为了训练大模型，以前大家主要用两种方法，但都有明显短板：

*   **方案 A：数据并行（Data Parallelism, DP）**

    *   **做法：** 假设你有 100 张显卡，你把完整的模型复制 100 份，每张卡放一份。然后每张卡吃不同的数据，算完后大家把梯度汇总，更新模型。

    *   **缺陷：** **极度浪费！** 既然大家的模型都是一模一样的，为什么要存 100 份副本？每张显卡的显存都被重复的内容填满了，导致单张卡能承载的模型上限很低。

*   **方案 B：模型并行（Model Parallelism, MP）**

    *   **做法：** 把一个大模型切开。比如前 10 层放在显卡 A，后 10 层放在显卡 B。或者把每一层的矩阵切开分给不同显卡。

    *   **缺陷：** **效率低、难实现。** 显卡之间需要频繁“聊天”（通信），如果显卡 A 还没算完，显卡 B 就得干等着（气泡效应），导致计算资源闲置。而且代码写起来非常复杂。

**总结痛点：** 数据并行（DP）效率高但显存浪费严重；模型并行（MP）省显存但效率低且复杂。

***

### 3. 本论文提出了何种解决方案？为什么能解决？

**解决方案：ZeRO (Zero Redundancy Optimizer)**

**核心思路：** ZeRO 的核心思想非常直观——**去除冗余（Zero Redundancy）**。它基于数据并行（DP）的架构，但是**不再让每张显卡都存完整的模型**。

你可以把 ZeRO 想象成一群人一起拼图：

*   **以前（数据并行）：** 每个人手里都有一幅**完整**的拼图，大家各拼各的。

*   **ZeRO（数据并行 + 分片）：** 把这幅拼图撕碎，**每个人只拿一小块碎片**。当我要用到你手里的那块碎片时，我临时找你借来看一眼，算完我就忘了（释放显存），但我手里的那一小块我一直存着。

**具体实施（三个阶段）：**

ZeRO 将显存节省分为了三个等级（也就是论文中的 ZeRO-DP 三个阶段），循序渐进地把东西“切碎”分给各张显卡：

1.  **ZeRO Stage 1（切分优化器状态 $P_{os}$）：**

    *   最占地方的“优化器状态”（比如 Adam 的动量）不再每张卡都存全量的。而是切分成 N 份，每张卡只负责维护 $\frac{1}{N}$ 的优化器状态。
    *   **效果：** 显存瞬间节省了 4 倍左右！且几乎不影响通信速度。

2.  **ZeRO Stage 2（切分梯度 $P_{g}$）：**

    *   在 Stage 1 的基础上，把“梯度”也切分了。每张卡只存自己负责的那部分梯度。

    *   **效果：** 显存进一步节省，大概能省 8 倍。

3.  **ZeRO Stage 3（切分模型参数 $P_{p}$）：**

    *   最极致的一步。连“模型参数”本身也切分了。每张卡只存 $\frac{1}{N}$ 的参数。
    *   **疑问：** 既然参数都切碎了，怎么做前向传播（算结果）？
    *   **解答：** 当显卡 A 需要计算第一层时，它发现自己只有第一层的一部分参数，它就向其他显卡广播：“把你们手里的第一层参数发给我！” 凑齐后计算，**算完立刻删掉别人的参数**，只保留自己那份。
    *   **效果：** 显存占用与显卡数量成线性反比。如果有 64 张卡，每张卡只需要存 $\frac{1}{64}$ 的模型。这使得训练万亿参数模型成为可能。

***

### 4. 方案的核心创新点在哪里？

1.  **鱼和熊掌兼得（Memory vs. Efficiency）：** 在此之前，大家认为“省显存”就得“牺牲计算效率”。ZeRO 证明了我们可以**保留数据并行（DP）的高效率**，同时获得**模型并行（MP）的显存优势**。它通过巧妙的通信机制（Broadcast/Reduce），让通信量并没有显著增加（通信量和传统 DP 差不多），但显存占用大幅下降。

2.  **线性的显存扩展能力：** 这是最震撼的创新。传统的 DP 增加显卡并不能增加能训练的模型大小上限。而 ZeRO 做到：**显卡越多，能训练的模型就越大**。这直接铺平了通往超大模型的道路。

3.  **对开发者透明（易用性）：** 对于写代码的学生来说，使用 ZeRO 不需要像模型并行那样去重写模型架构。你依然像写普通代码一样，ZeRO 框架（如 DeepSpeed）会在底层帮你搞定所有的切分、通信和拼接。

### 一句话总结

**ZeRO 通过将模型训练中原本重复存储的“三座大山”（优化器状态、梯度、参数）切碎并分散存储到多张显卡上，并在计算需要时动态拼凑，从而在不牺牲计算速度的前提下，极大地降低了单张显卡的显存压力，让训练万亿参数模型成为现实。**

## 思考一

1.  反向传播的梯度为什么需要存储在显存里，而不能边用边算？
2.  用通俗的语言解释一下Adam优化器的工作原理，“动量”和“方差”是什么？为什么需要存储？
3.  优化器状态具体是如何切分的？Stage1时切成N份，为什么显存只节省了4倍而不是N倍？
4.  梯度是如何切分的，为什么梯度只节省了8倍而不是N倍？
5.  模型参数是怎么切分的？怎么能做到切分完后，通信量和传统DP差不多？
6.  ZeRO和Megatron-LM都是为了节省显存，两者相比各自的优缺点是什么？
7.  ZeRO和Megatron-LM是否能同时使用？同时使用与单独使用相比，两种方法需要做什么调整吗？比较一下在实践中，同时使用，以及各自单独使用，内存的节省情况。

***

同学你好！很高兴看到你已经开始思考更深层的问题了。这说明你不仅听懂了“是什么”，还在琢磨“为什么”和“怎么做”。

这些问题非常核心，触及了分布式训练的底层逻辑。我们一个个来拆解。

***

### 1. 反向传播的梯度为什么需要存储在显存里，而不能边用边算？

这是一个非常直观的疑问。我们习惯了“流水线”作业，为什么梯度非要囤积起来？

**根本原因：优化器（Optimizer）的工作机制。**

想象你在指挥一场战役（训练模型）：

1.  **前向传播（Forward）：** 士兵冲锋，计算损失（Loss）。

2.  **反向传播（Backward）：** 统计每位士兵（参数）应该向左还是向右调整（计算梯度）。

3.  **参数更新（Step）：** **统一**下令，所有人一起调整位置。

**为什么不能“算出一个梯度，就更新一个参数”？**

*   **数学约束：** 绝大多数深度学习优化器（SGD、Adam等）是基于\*\*Batch（批次）\*\*的。我们需要看完这一批数据（比如 512 张图片）所有的反馈，取一个平均值，才能决定这一步往哪里走。如果看一张图就改一次参数，路线会极其抖动，很难收敛。

*   **依赖关系：** 在反向传播过程中，第 5 层的梯度计算可能依赖于第 6 层的权重。如果你在算完第 6 层的梯度后立刻更新了第 6 层的权重，那么当计算传导到第 5 层时，它面对的是“新版”的第 6 层，这会导致数学上的错乱（梯度计算需要基于“做前向传播时”的那套参数）。

所以，梯度必须先\*\*暂存（Accumulate）\*\*在显存里，等所有参数的梯度都算好了，再由优化器统一“结算”更新。

***

### 2. 用通俗语言解释 Adam 优化器及其“动量”和“方差”

Adam 是目前最流行的大模型“训练教官”。为了让模型学得快又稳，它比普通的 SGD（随机梯度下降）多存了两样法宝。

**形象比喻：下山** 我们要训练模型找到 Loss 最低点，就像蒙着眼下山。

*   **普通 SGD：** 感觉脚下哪个方向是下坡，就迈一步。

    *   *缺点：* 遇到平地走得慢，遇到坑洼容易乱跳。

*   **Adam 的法宝 1：动量（Momentum，一阶矩）——“惯性”**

    *   *原理：* 如果你之前一直全速往东跑，下一秒就算脚下有点小坑让你往西，你也会因为**惯性**继续稍微往东偏一点。

    *   *作用：* 它可以冲过小坑，加速收敛。

    *   *存储：* 既然要模拟惯性，就需要记住\*\*“过去一段时间的速度和方向”\*\*。这就占用了一份显存（和参数量一样大）。

*   **Adam 的法宝 2：方差（Variance，二阶矩）——“路况适应”**

    *   *原理：* 也就是自适应学习率。如果某条路非常陡峭（梯度变化大，方差大），为了安全，我们要步子迈小点；如果路很平坦（梯度变化小），步子就迈大点。

    *   *作用：* 防止在陡峭的地方摔死（梯度爆炸），在平坦的地方磨叽（收敛慢）。

    *   *存储：* 需要记住\*\*“过去一段时间路面的颠簸程度”\*\*。这又占用了一份显存（和参数量一样大）。

**总结：** 为了让 Adam 能够拥有“惯性”和“自适应步伐”，它必须为**每一个参数**都记录一份动量和一份方差。这就是为什么它特别吃显存。

***

### 3. Stage 1 切分优化器状态：为什么只节省了 4 倍而不是 N 倍？

这是一个非常经典的数学账。

假设我们用**混合精度训练**（这是训练大模型的标配），显存里的“常住居民”是这样的：

1.  **模型参数（FP16）：** 2 字节

2.  **梯度（FP16）：** 2 字节

3.  **优化器状态（FP32）：**

    *   参数的主副本（Master Weights）：4 字节（为了保证精度，优化器里存一份高精度的）
    *   动量（Momentum）：4 字节
    *   方差（Variance）：4 字节
    *   **合计：12 字节**

**算总账：** 一个参数在显存里总共占用 $2 + 2 + 12 = 16$ 字节。 其中，**优化器状态占了 12 字节，刚好是总量的 3/4（75%）。**

**Stage 1 做了什么？** 它把最占地方的 **优化器状态（12字节）** 切分成了 N 份。 当 $N$ 很大时，每张卡上存的优化器状态约等于 0。

**节省结果：**

*   **原本：** $2 + 2 + 12 = 16$ 字节
*   **Stage 1：** $2 + 2 + (12 / N) \approx 4$ 字节
*   **计算：** $16 \div 4 = 4$ 倍。

**为什么不是 N 倍？** 因为 Stage 1 **没有切分** 模型参数（2字节）和 梯度（2字节）。这两部分还是雷打不动地每张卡存一份，所以显存占用的底线就是这 4 字节。

***

### 4. Stage 2 切分梯度：为什么是 8 倍而不是 N 倍？

接上面的算账，进入 Stage 2：

**Stage 2 做了什么？** 在 Stage 1 的基础上，把 **梯度（2字节）** 也切分了。

**节省结果：**

*   **Stage 1：** 4 字节
*   **Stage 2：** 参数（2字节） + 梯度（$2/N$） + 优化器状态（$12/N$） $\approx 2$ 字节。
*   **对比原始（16字节）：** $16 \div 2 = 8$ 倍。

**为什么不是 N 倍？** 因为 Stage 2 依然\*\*保留了完整的模型参数（2字节）\*\*在每张卡上。这是最后的底线。

***

### 5. 模型参数是怎么切分的？怎么做到通信量和传统 DP 差不多？

到了 Stage 3，我们把最后的 **参数（2字节）** 也切了。每张卡只存 $1/N$ 的参数。

**怎么做前向/反向传播？**

*   **随用随取（Broadcast）：** 当 GPU 1 需要计算第 1 层时，它发现自己只有第 1 层的 $1/N$ 参数。它会广播请求，让其他 GPU 把剩下的部分发给它。
*   **用完即焚：** 算出结果后，GPU 1 立刻把借来的参数删掉，只保留自己那 $1/N$。

**既然要借来借去，通信量为什么没爆炸？**

这涉及到一个巧妙的通信转换：

*   **传统数据并行 (DP)：** 每一步训练结束，大家都有不同的梯度，需要做一个 **All-Reduce** 操作（所有卡把梯度加起来，再同步给所有人）。All-Reduce 的通信量是 $2 \times \text{模型大小}$。

*   **ZeRO Stage 3：**

    *   它取消了最后那个巨大的 All-Reduce。

    *   取而代之的是，在每一层计算前，做一个 **All-Gather**（把参数凑齐），计算完梯度后，做一个 **Reduce-Scatter**（把梯度归位并累加）。

    *   数学证明显示：**Scatter + Gather 的通信总量$\approx$传统 DP 的 All-Reduce 通信总量。**

**通俗理解：** <span style="background-color: #ffd40080">原来是“大家闷头算完全部，最后搞一次超大的大汇合（同步梯度）”。 现在是“算每一小步之前，先搞一次小汇合（凑参数），算完立刻把结果分发回去（分梯度）”。 </span>**<span style="background-color: #ffd40080">总量没变，只是化整为零了。</span>**<span style="background-color: #ffd40080"> 所以通信开销是可以接受的。</span>

***

### 6. ZeRO 和 Megatron-LM 的优缺点对比

这两者都是大模型训练的神器，但侧重点不同。

*   **ZeRO (DeepSpeed)**

    *   **本质：** 优化的**数据并行 (Data Parallelism)**。

    *   **优点：**

        1.  **通用性强：** 几乎不需要改模型代码，改几行配置就能用。

        2.  **显存节省极致：** ZeRO-3 可以让显存随 GPU 数量线性下降。

    *   **缺点：**

        1.  **通信频次高：** Stage 3 在每一层计算都要通信，对网络延迟（Latency）非常敏感。如果网速慢，训练会变慢。

*   **Megatron-LM**

    *   **本质：** **张量并行 (Tensor Parallelism, TP)**。它把一个巨大的矩阵乘法切开，分给不同 GPU 算。

    *   **优点：**

        1.  **减少单卡计算量：** 不仅分摊了显存，还把计算压力分摊了。
        2.  **适合超大层：** 如果某一层特别大（比如 Hidden Size 很大），大到单卡放不下，ZeRO 也没办法（<span style="background-color: #ffd40080">因为 ZeRO 在计算那一瞬间需要把该层参数凑齐</span>），必须用 TP 切开算。

    *   **缺点：**

        1.  **侵入性强：** 需要重写模型代码（Linear 层要改成 ParallelLinear）。

        2.  **通信极度频繁：** 每一层内部都要做 All-Reduce，必须依赖 NVLink 这种超高速卡间互联。通常只能在同一台服务器内部的 GPU 之间使用。

***

### 7. ZeRO 和 Megatron-LM 能否同时使用？

**答案：必须能！而且这是训练千亿/万亿参数模型的“标准答案”。**

这被称为 **3D 并行（3D Parallelism）**：

1.  **Data Parallelism (ZeRO)**
2.  **Tensor Parallelism (Megatron)**
3.  **Pipeline Parallelism (流水线并行)**

**为什么要混用？**

*   **单独用 ZeRO-3：** 如果卡太多（比如 1000 张），把参数切成 1000 份，每次计算都要从 999 个人那里借参数，通信碎片化太严重，效率会掉。

*   **单独用 Megatron：** 只能在单机（8卡）内搞，跨机器搞不定（网络太慢）。

**最佳实践（混合模式）：** 假设你有 1000 张卡，分布在 125 台机器上（每台 8 卡）。

1.  **在每台机器内部（8卡）：** 使用 **Megatron (TP)**。把模型切开。这样每个 GPU 只需要负责模型运算量的 1/8。

2.  **在机器之间（跨节点）：** 使用 **ZeRO (DP)**。把这切好的 1/8 模型，再通过 ZeRO 的方式去除冗余。

**内存节省情况对比：**

*   **单独 ZeRO：** 显存占用 $\propto 1/N_{total}$。但 $N$ 太大通信受不了。

*   **单独 Megatron：** 显存占用 $\propto 1/N_{node}$（最多除以 8）。省得不够多。

*   **混合使用：** 显存占用$\propto \frac{1}{N_{TP} \times N_{ZeRO}}$。

    *   Megatron 先把模型变小了（比如变成原来的 1/8）。

    *   ZeRO 再把这 1/8 的模型的优化器状态、梯度再切分。

    *   **效果：** 既解决了超大层放不下的问题，又解决了显存不够的问题，还平衡了通信效率。

希望这个解读能帮你彻底厘清这些概念！

## 思考二

1.  ZeRO的三个Stage是同时做的吗？还是在不同时间分别做的？为什么不同时做？
2.  同时使用Megatron和ZeRO时，整个工作流是什么样的？

***

这两个问题问到了实际操作中最核心的架构设计逻辑。特别是第一个问题，是一个非常常见的误区；第二个问题则是当前训练超大模型（如 GPT-4、Llama 3）的标准工业界实战流程。

我们来逐一拆解。

***

### 问题 1：ZeRO 的三个 Stage 是同时做的吗？还是在不同时间分别做的？

**结论：不是不同时间做的，也不是“同时”做三个。它们是三个“等级”或“模式”。你只能选其中一个等级来运行。**

很多同学看到 Stage 1, 2, 3，会以为是“先做步骤1，再做步骤2...”。**完全错误。** 这就像你玩游戏的画质设置：

*   **Stage 1：** 低画质（只省一点显存，速度最快）。

*   **Stage 2：** 中画质（省更多显存，速度稍慢）。

*   **Stage 3：** 高画质（省显存到极致，通信压力大，速度相对最慢）。

**它们是包含关系（递进关系）：**

*   当你开启 **Stage 2** 时，它默认已经包含了 Stage 1 的优化（既切分优化器，又切分梯度）。

*   当你开启 **Stage 3** 时，它默认包含了 Stage 1 和 Stage 2 的所有优化，并加上了参数切分。

**为什么不同时做？（或者说为什么不直接默认全开 Stage 3？）** 既然 Stage 3 省显存最厉害，为什么不无脑用 Stage 3？ **因为有代价。**

*   **通信开销：** Stage 3 为了省显存，把参数都切碎了。每次计算都要去别人那里“借”参数，这会带来巨大的**通信延迟**。

*   **速度权衡：** 如果你的显卡显存够大（比如你有 80GB 的 A100），单纯用 Stage 1 或 Stage 2 就能跑得起来，那就没必要开 Stage 3。因为 Stage 1/2 通信少，跑得更快。

**总结：** 这是一个\*\*“显存 vs 速度”的权衡开关\*\*。你根据你的硬件条件，在开始训练前在配置文件里选定一个 Stage。

***

### 问题 2：同时使用 Megatron (TP) 和 ZeRO (DP) 时，整个工作流是什么样的？

这是一个非常精彩的\*\*3D 并行（3D Parallelism）\*\*实战场景。这是目前训练千亿级模型的主流架构。

为了让你听懂，我们建立一个具体的场景：

*   **硬件：** 2 台机器（Node A, Node B）。

*   **显卡：** 每台机器 2 张卡。总共 4 张卡（GPU 0, 1, 2, 3）。

    *   Node A: GPU 0, GPU 1
    *   Node B: GPU 2, GPU 3

*   **策略：**

    *   **Megatron (TP = 2)：** 在机器**内部**把模型切两半。

    *   **ZeRO (DP = 2)：** 在机器**之间**做数据并行。

#### **整个工作流（Step-by-Step）：**

我们把这个过程分为**静态切分**和**动态训练**两部分。

#### **第一步：静态切分（模型怎么放？）**

训练还没开始，模型已经加载到显存里了。

1.  **Megatron 切一刀（横向）：**

    *   模型太大了，单卡放不下。Megatron 说：“GPU 0 和 GPU 1，你们俩是一组。GPU 0 存模型的前半截（左半边矩阵），GPU 1 存后半截（右半边矩阵）。”

    *   同理，GPU 2 和 GPU 3 也是这样存。

    *   **此时：** (GPU 0 + GPU 1) 是一个完整的模型副本；(GPU 2 + GPU 3) 是另一个完整的模型副本。

2.  **ZeRO 切一刀（纵向）：**

    *   现在有两个完整的模型副本（Node A 一套，Node B 一套）。ZeRO 说：“太浪费了！我要把**优化器状态**切分。”

    *   针对模型的“左半边矩阵”（GPU 0 和 GPU 2 负责的部分）：ZeRO 让 GPU 0 维护第 1-5 层的优化器状态，GPU 2 维护第 6-10 层的。

    *   针对模型的“右半边矩阵”（GPU 1 和 GPU 3 负责的部分）：同理切分。

**这就是“混合”的状态：模型被 Megatron 物理切开了，而剩下部分的维护数据被 ZeRO 再次切分了。**

***

#### **第二步：动态训练（一次迭代的数据怎么跑？）**

假设来了一批数据（Batch Size = 4），我们开始训练：

1.  **数据分配（DP）：**

    *   Node A (GPU 0, 1) 拿到前 2 条数据。
    *   Node B (GPU 2, 3) 拿到后 2 条数据。

2.  **前向传播（Forward）—— Megatron 的主场：**

    *   在 Node A 内部，GPU 0 和 GPU 1 必须紧密配合。

    *   算第一层时：GPU 0 算左半边，GPU 1 算右半边。算完立刻通过 **NVLink**（极高带宽）交换结果，拼成完整结果，再传给下一层。

    *   *注意：此时 Node A 和 Node B 互不理睬，各算各的数据。*

3.  **反向传播（Backward）：**

    *   算出梯度。同样，Node A 内部 GPU 0/1 狂聊（All-Reduce），算出它们这组数据的梯度。Node B 同理。

4.  **优化器更新（Optimizer Step）—— ZeRO 的主场：**

    *   现在，GPU 0（Node A）手里有“左半边模型”的梯度，GPU 2（Node B）手里也有“左半边模型”的梯度。

    *   **ZeRO 介入：** 它们之间进行通信（通常跨机器，网速较慢）。

    *   **Reduce-Scatter：** 它们不互相把梯度全发给对方，而是说：“前一半层的梯度给 GPU 0 汇总，后一半层的梯度给 GPU 2 汇总”。

    *   **更新权重：** GPU 0 拿着汇总好的梯度，更新它负责的那部分优化器状态，算出新的权重。

    *   **All-Gather：** 更新完后，GPU 0 把最新的权重广播回给 GPU 2。

    *   *注意：此时是 GPU 0 和 GPU 2 聊（处理左半边），GPU 1 和 GPU 3 聊（处理右半边）。*

***

#### **总结这个混合工作流的精髓**

*   **Megatron (TP)** 负责解决\*\*“单卡算力不够、模型层太大放不下”**的问题。它发生在**高频的计算过程中\*\*，所以必须要在同一台机器内部，用最快的线（NVLink）连着。

*   **ZeRO (DP)** 负责解决\*\*“多组显卡之间显存冗余”**的问题。它发生在**计算结束后的更新阶段\*\*，通信频率相对较低，所以可以跨机器，走慢一点的网线也还能接受。

**简单记忆：** **切蛋糕（Megatron）** 让每个人只吃一小块（减少计算和参数）； **AA制买单（ZeRO）** 让大家分摊账单（显存），最后共享结果。

## 思考三

1.  如果使用普通SGD，是不是只需要存一个batch的后一层的梯度即可，而不需要存全部梯度？
2.  模型参数和梯度是FP16，优化器状态是FP32，计算过程中是需要FP16的算力还是FP32的算力？
3.  在模型推理时，会使用ZeRO和Megatron-LM技术吗？
4.  ZeRO的三个Stage的数据流分别是什么样的，每个Stage的通讯量各有多大？

***

这一组问题非常硬核，直击大模型训练的底层细节。我们来逐一拆解，继续保持通俗易懂的风格。

### 1. 如果使用普通 SGD，是不是只需要存一个 Batch 的后一层的梯度即可，而不需要存全部梯度？

**答案：不可以，必须存全部梯度。**

这是一个非常容易产生的误解。很多同学以为反向传播是“算一层、改一层、扔一层”。但实际上，\*\*反向传播（算梯度）**和**参数更新（改权重）\*\*是两个完全分离的阶段。

**为什么不能“边算边改”？** 这就好比你在写一篇论文（模型训练）：

1.  **反向传播（Backprop）：** 是教授在给你**批改**作业。他从最后一页看到第一页，在每一页上用红笔写下修改意见（计算梯度）。

    *   *注意：* 此时教授是基于你“当前的原文”提出的意见。

2.  **参数更新（Optimizer Step）：** 是你根据意见**重写**论文。

**如果你“边算边改”会发生什么？** 假设教授刚看完第 10 页，你就立刻把第 10 页改写了。 当教授继续看第 9 页时，第 9 页的内容逻辑是依赖第 10 页的。但他看到的第 10 页已经被你改得面目全非了！这时他对第 9 页提出的修改意见（梯度）就会基于错误的信息，导致逻辑崩塌（数学上不再收敛）。

**结论：** 所有的 $dL/dW$（权重梯度）必须一直暂存在显存里，直到所有层（0 到 N 层）的梯度都算完，优化器才会统一发令：“好，现在大家一起根据刚才的意见更新权重！”

***

### 2. 模型参数和梯度是 FP16，优化器状态是 FP32，计算过程中是需要 FP16 的算力还是 FP32 的算力？

**答案：主要用 FP16 算力（计算），辅以 FP32 算力（更新）。**

这就是所谓的**混合精度训练（Mixed Precision Training）**。

*   **繁重的体力活（FP16）：**

    *   在大模型训练中，99% 的计算量在于**矩阵乘法（Matrix Multiplication）**。

    *   这部分工作在前向传播和反向传播中进行。

    *   使用的是 **FP16**（或者 BF16）。

    *   *硬件层面：* NVIDIA 的 **Tensor Core** 专门就是为了疯狂加速 FP16 的矩阵运算而设计的。

*   **精细的会计活（FP32）：**

    *   这部分工作在优化器更新（Optimizer Step）阶段。

    *   我们需要把 FP16 的梯度加到 FP32 的参数主副本上。

    *   使用的是 **FP32**。

    *   *原因：* 梯度的数值通常非常小（比如 0.00001）。如果用 FP16（精度低），这个微小的变化加到大权重上可能直接被当作 0 忽略掉了（下溢出）。所以必须用高精度的 FP32 来累积这些微小的进步。

**总结：** 显卡在“跑模型”时在做 FP16 的乘法（快且省显存），在“更新参数”时在做 FP32 的加法（慢但准）。

***

### 3. 在模型推理（Inference）时，会使用 ZeRO 和 Megatron-LM 技术吗？

**答案：Megatron-LM 必用，ZeRO 看情况（主要用 ZeRO-3 的思想）。**

**1. Megatron-LM (张量并行 TP)：**

*   **必用场景：** 当模型太宽，单张显卡根本装不下一层参数时（比如 GPT-3 175B，参数量巨大）。

*   **推理应用：** 就算不做训练，你也没法把整个模型塞进一张卡。所以必须用 Megatron 的切分方式，让 8 张卡每人拿模型的一部分，一起完成推理。

**2. ZeRO (数据并行 DP)：**

*   **ZeRO-1 / ZeRO-2：** **推理时完全不用。**

    *   因为推理不需要“梯度”，也不需要“优化器状态”。这两座大山直接没了。显存里只剩“模型参数”。

*   **ZeRO-3 (模型参数切分)：** **推理时非常有用（称为 ZeRO-Inference 或 Offload）。**

    *   如果你的模型大到显存放不下（即使没有梯度），你依然可以用 ZeRO-3 的思想：把模型参数存在 CPU 内存（RAM）里。

    *   **推理流程：** 当显卡要算第 1 层时，从 CPU 内存把第 1 层参数搬到显卡显存，算完扔掉；再搬第 2 层...

    *   这让你可以用一张 4090 跑 70B 的大模型（虽然速度会慢，因为受限于 PCIE 带宽）。

***

### 4. ZeRO 的三个 Stage 的数据流分别是什么样的，每个 Stage 的通讯量各有多大？

我们需要对比标准的数据并行（DP）来看。假设模型大小为 $\Psi$。 **标准 DP 通信量：** $2\Psi$（一次 All-Reduce）。

#### **Stage 1 & Stage 2 (核心：Scatter + Gather)**

其实在工业界实现中，Stage 1 和 Stage 2 的通信模式几乎一样，Stage 2 是最典型的代表。

*   **数据流：**

    1.  **反向传播结束：** 每张卡算出了自己的梯度（Partial Gradients）。

    2.  **Reduce-Scatter（通信）：** 大家不交换全部梯度。GPU 0 说：“把你们手里第 1 层参数的梯度都发给我，我负责加总。” GPU 1 说：“把第 2 层的都给我...”

        *   *结果：* 每张卡手里只有**完整梯度的$\frac{1}{N}$**。

    3.  **优化器更新：** 每张卡只更新自己负责的那  $\frac{1}{N}$  的权重（需要对应的  $\frac{1}{N}$  优化器状态）。

    4.  **All-Gather（通信）：** 更新完了，GPU 0 把最新的第 1 层参数广播给所有人，GPU 1 广播第 2 层...

        *   *结果：* 大家又都有了完整的、更新后的新模型，准备下一轮前向传播。

*   **通信量：**

    *   Reduce-Scatter ( $\Psi$ ) + All-Gather ( $\Psi$ ) = **$2\Psi$**。

    *   **结论：** ZeRO-2 的通信量和普通 DP **完全一样**！这就是为什么它能在不牺牲速度的情况下省显存。

#### **Stage 3 (核心：随用随取)**

Stage 3 比较特殊，因为它连“完整的模型”都不存了。

*   **数据流（以一层为例）：**

    1.  **前向传播 - 这一层开始：** 我手里只有这层参数的  $\frac{1}{N}$ 。

    2.  **All-Gather（通信）：** 找别人要把剩下的凑齐。

    3.  **计算：** 算出结果。

    4.  **丢弃：** 马上把借来的参数删了（省显存）。

    5.  **反向传播 - 这一层开始：** 又要算这一层的梯度了。

    6.  **All-Gather（通信）：** **再借一次参数！**（因为刚才删了，但算梯度需要用到权重）。

    7.  **计算：** 算出梯度。

    8.  **Reduce-Scatter（通信）：** 算出梯度后，立刻把梯度分发给负责人（同 Stage 2），自己手里的梯度删掉。

*   **通信量：**

    *   前向 All-Gather ( $\Psi$ ) + 反向 All-Gather ( $\Psi$ ) + 反向 Reduce-Scatter ( $\Psi$ ) = **$3\Psi$**。

    *   **结论：** ZeRO-3 的通信量大约是普通 DP 的 **1.5 倍**。

    *   *注：* 虽然通信多了，但因为它可以重叠计算和通信（Computation-Communication Overlap），实际训练速度在带宽足够时并不会慢太多。

**一句话总结通信量：**

*   **ZeRO-1/2** 通信量 = **1x** 标准 DP（不慢）。

*   **ZeRO-3** 通信量 ≈ **1.5x** 标准 DP（稍微多一点，换来了巨大的显存空间）。

## 思考四

1.  请用梯度和权重的更新公式推导的方式讲清楚以下逻辑："所有的  $dL/dW$ （权重梯度）必须一直暂存在显存里，直到所有层（0 到 N 层）的梯度都算完，优化器才会统一发令：好，现在大家一起根据刚才的意见更新权重！”

2.  如果stage1和stage2的通讯量是一样的，那用户有什么理由选stage1，而不选stage2呢？换句话说，stage2比stage1在节省更多内存的情况下，会有什么其他损失？

3.  stage1和stage2的通讯量虽然和普通DP一样，但延迟是不是不同的？即普通DP的通讯频率是每batch 一次，而zero的stage1和stage2是每Layer一次？

***

这三个问题非常犀利，特别是第一个和第三个，触及了深度学习的数学原理和系统实现的底层细节。

我们来逐一拆解。

### 1. 用公式推导：为什么必须存完所有梯度才能更新？

这是一个涉及\*\*链式法则（Chain Rule）\*\*严谨性的问题。

**核心逻辑：** 梯度的定义是损失函数 $L$ 对参数 $W$ 在\*\*“当前位置”\*\*的导数。如果你在计算过程中改变了“位置”（更新了某层参数），后续的梯度计算就会基于错误的位置，导致数学上的崩塌。

#### **推导演示**

假设一个简单的 2 层神经网络：

*   输入： $x$

*   第 1 层： $h = f_1(W_1, x)$

*   第 2 层： $y = f_2(W_2, h)$

*   损失： $L = Loss(y, target)$

**前向传播（Forward）：** 我们记录下了当时的 $W_1, W_2, h$。此时整个系统的状态是**冻结**的快照。

**反向传播（Backward）：** 我们要算 $\frac{\partial L}{\partial W_1}$ 和 $\frac{\partial L}{\partial W_2}$。

1.  **先算第 2 层梯度（$W_2$）：** $G_2 = \frac{\partial L}{\partial W_2} = \frac{\partial L}{\partial y} \cdot \frac{\partial y}{\partial W_2}$ *这一步没问题。*

2.  **关键分歧点：**

    *   **正确做法：** 把  $G_2$  存进显存，**保持$W_2$不变**，继续算  $W_1$  的梯度。

    *   **错误做法（边算边改）：** 算出  $G_2$  后，立刻更新  $W_2$ ： $W_2^{new} = W_2 - \eta \cdot G_2$ 此时，显存里的  $W_2$  变成了  $W_2^{new}$ 。

3.  **再算第 1 层梯度（$W_1$）：** 根据链式法则，$\frac{\partial L}{\partial W_1}$的公式是： $\frac{\partial L}{\partial W_1} = \frac{\partial L}{\partial y} \cdot \underbrace{\frac{\partial y}{\partial h}}_{\text{依赖 } W_2} \cdot \frac{\partial h}{\partial W_1}$注意中间这一项$\frac{\partial y}{\partial h}$。在公式中，它实际上等于$W_2$（如果是线性层）。

    *   **我们需要的是：** 计算前向传播那一瞬间的梯度，所以必须用 **$W_2$(旧值)**。

    *   **实际发生的（如果你提前更新了）：** 系统会去读显存，读到了 **$W_2^{new}$**。

**结论：** 如果你用了 $W_2^{new}$ 去计算 $W_1$ 的梯度，你算出来的梯度**既不是针对旧参数的，也不是针对新参数的**，而是一个逻辑错乱的中间值。这会导致模型无法收敛。

**更重要的理由（分布式视角）：** 在 ZeRO 这种分布式训练中，单张卡算出的梯度 $g_{local}$ 只是局部数据的结果。 全局梯度 $G_{global} = \frac{1}{N} \sum g_{local}$。 如果不等所有层算完，也不等所有 GPU 通信完（All-Reduce），单张卡根本不知道真正的“更新方向”是什么，想更也更不了。

***

### 2. Stage 1 和 Stage 2 通讯量一样，为什么还要选 Stage 1？

这是一个非常敏锐的问题。从理论上看，Stage 2 全面优于 Stage 1（显存省更多，通讯量没变）。

**为什么还有人用 Stage 1？（或者说 Stage 2 的代价是什么？）**

虽然\*\*总通讯字节数（Bandwidth）**一样，但**通讯的效率（Latency/Overhead）\*\*略有不同。

1.  **通讯碎片的管理成本（CPU Overhead）：**

    *   **Stage 1 (All-Reduce):** 这是一个非常成熟、高度优化的操作（NCCL 库对此优化到了极致）。不管梯度怎么分布，一股脑全归约就行。

    *   **Stage 2 (Reduce-Scatter):** 需要更精细的管理。显卡 0 负责第 1-10 层，显卡 1 负责第 11-20 层...

    *   当模型层数非常多或者梯度切分不均匀时，Stage 2 需要 CPU 耗费更多算力去“指挥”哪些数据发给谁。这会带来轻微的 CPU 开销。

2.  **网络拓扑的敏感度：**

    *   在某些老旧的网络架构（非 InfiniBand，非 NVLink）或者拓扑结构复杂的集群中，All-Reduce（通常是环状算法 Ring-AllReduce）的稳定性可能略好于 Reduce-Scatter + All-Gather 的组合。

3.  **梯度累积（Gradient Accumulation）的便利性：**

    *   有些用户喜欢在本地魔改梯度（比如做一些很复杂的梯度裁剪、或者梯度惩罚），如果梯度在 Stage 1（本地存一份完整的），代码好写。
    *   如果用了 Stage 2，梯度算出来一部分就被“送走”归约了，本地只剩下一小块残片，想对完整梯度做全局操作会变得很麻烦。

**结论：** 在今天的实践中（特别是使用 DeepSpeed 框架），**绝大多数情况都推荐直接使用 Stage 2**。Stage 1 现在更多是作为一种“调试模式”或者“兼容旧代码”的选项存在。Stage 2 节省的 4 倍额外显存（梯度部分）带来的收益远大于那一点点潜在的 CPU 开销。

***

### 3. 普通 DP 是每 Batch 通讯一次？ZeRO 是每 Layer 一次？

**这是一个巨大的误区！**

首先澄清：**普通 DP (DDP) 绝对不是跑完整个 Batch（所有层）才通讯的。** 那样就太慢了，无法利用“计算与通信重叠”的优势。

#### **真实的工作流对比**

无论是普通 DP 还是 ZeRO 1/2，它们都采用了 **Bucketing（分桶）** 机制。

**1. 普通 DP (PyTorch DDP) 的通讯逻辑：**

*   **Buffer 桶：** DDP 会在显存里开几个桶（比如每个桶 25MB）。

*   **反向传播流：**

    *   算完最后一层的梯度 -> 丢进桶里。

    *   算完倒数第二层梯度 -> 丢进桶里。

    *   ...

    *   **触发：** 一旦**桶满了**（比如凑够了 25MB 数据），DDP 立刻触发异步 **All-Reduce**。

    *   **重叠：** 此时 GPU 继续算倒数第 N 层的梯度（计算），而网卡同时在传刚才那个桶的数据（通信）。

*   **频率：** 取决于桶的大小，通常是一个 Batch 里面会发生几十上百次通讯，而不是一次。

**2. ZeRO Stage 1 / Stage 2 的通讯逻辑：**

*   **逻辑完全一样！** 也是基于 Bucket 的。

*   ZeRO 也是在反向传播的过程中，梯度填满一个 Bucket，就立刻触发通信。

    *   Stage 1 触发 All-Reduce。
    *   Stage 2 触发 Reduce-Scatter。

*   **延迟对比：** 理论上 ZeRO 1/2 和普通 DP 的**通信频率和延迟是几乎一致的**。它们都极好地掩盖了通信时间。

**3. 真正的“每 Layer 一次”：ZeRO Stage 3**

*   只有 **Stage 3** 是特殊的。

*   因为它不存参数，所以它必须在**前向传播**算每一层之前，先把参数 Fetch 过来（All-Gather）。

*   这种通信是**阻塞式**的（必须等参数到了才能算），或者是需要极高难度的预取（Prefetch）技术来掩盖。

*   所以，Stage 3 的延迟感最明显，且通信频率严格受限于层数。

**总结：**

*   **普通 DP / ZeRO-1 / ZeRO-2：** 通信是\*\*流式（Streaming）\*\*的，基于桶大小，频率高但重叠性好，几乎不卡顿。

*   **ZeRO-3：** 通信是\*\*按层（Layer-wise）\*\*的，在前向和反向过程中都要频繁通信，延迟影响最大。
