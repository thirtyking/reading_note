---
tags: []
parent: '[DS-Coder] DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence'
collections:
    - 学习范式
$version: 2274
$libraryID: 1
$itemKey: 3LUUP9S4

---
\[2024-01]\[DS-Coder] DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence

# \[DS-Coder] DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence

## 概述

你好！很高兴能以资深 AI 研究员的身份为你解读这篇具有里程碑意义的论文：**《DeepSeek-Coder: When the Large Language Model Meets Programming - The Rise of Code Intelligence》**。

这篇文章介绍了 DeepSeek 团队开发的 DeepSeek-Coder 系列模型，它在开源社区引起了很大轰动。下面我为你详细拆解。

***

### 1. 本论文要解决什么问题？为什么很重要？

**核心问题：** 缩小开源代码大模型与闭源模型（如 GPT-4、GPT-3.5）之间的性能差距。

**重要性：**

*   **研究受限：** 像 GPT-4 这种闭源模型虽然强大，但研究者无法了解其训练数据和具体实现，限制了学术进步。

*   **开发成本：** 企业和开发者希望有高性能且能本地部署的“编程助手”，以保护代码私密性并降低使用商业 API 的成本。

*   **生产力：** 编程是 AI 最能落地、提升效率最高的领域之一，提升“代码智能”意味着能自动修 Bug、写代码、甚至进行架构设计。

***

### 2. 解决这个问题的难点在哪里？

**难点：**

1.  **文件之间的关联性：** 之前的模型（如 StarCoder）大多是在“单个文件”级别上训练的。但现实编程中，一个项目有几百个文件，A 文件会调用 B 文件里的函数。如果模型只看单文件，它就无法理解复杂的项目逻辑。

2.  **“中间补全”能力差：** 传统的模型习惯从头写到尾，但在实际编程中，程序员经常在代码中间插一句话。如何让模型学会“根据上下文补全中间代码”是一个技术活。

3.  **多语言平衡：** 全球有几十种常用编程语言，如何让模型既懂 Python 这种大众语言，又懂 C++、Go 甚至 Verilog 这种专业语言？

**之前的方案：** 如 CodeLlama、StarCoder。它们虽然不错，但在处理跨文件逻辑和极长代码时，表现依然不如 GPT 系列稳定，且模型规模较小时性能滑坡严重。

***

### 3. 本论文提出了何种解决方案？

DeepSeek 团队推出了 **DeepSeek-Coder 系列**（从 1.3B 到 33B 参数不等），核心思路如下：

*   **海量且高质量的训练数据：** 他们从零开始，在 **2 万亿 (2 Trillion)** 标记的代码库上进行训练，涵盖了 87 种编程语言。

*   **项目级（Repository-level）预训练：** 这是点睛之笔。他们不再把文件拆散，而是把整个代码仓库里的文件按逻辑顺序排好，让模型学习文件之间的引用关系。

*   **FIM（Fill-In-Middle）策略：** 在训练时，故意挖掉代码中间的一部分让模型去填，增强它的代码补全能力。

*   **长文本窗口：** 支持 16K 的上下文窗口，意味着模型可以“读”完更长的代码段而不忘掉开头。

**为什么能解决？** 因为这种方案更贴近程序员的真实工作模式：**在整个项目背景下，不仅能生成新代码，还能在现有代码中间修修补补。**

***

### 4. 方案的核心创新点在哪里？

1.  **仓库级数据构造（最重要）：** 论文提出了一个 **“拓扑排序”算法 (Topological Sort)**。它会分析项目中文件的依赖关系，确保模型先学习“被调用”的文件，再学习“调用者”的文件。这模拟了人类学习代码项目的逻辑。

2.  **FIM 策略的深度优化：** 论文通过实验发现，虽然 100% 使用 FIM 训练对补全效果最好，但会伤害模型从头生成代码的能力。最终他们选择了 50% 的平衡点。

3.  **小身材大能量：** DeepSeek-Coder **7B（70 亿参数）** 版本的表现甚至能和竞争对手 **34B（340 亿参数）** 的模型平起平坐，效率极高。

***

### 5. 本方案有什么局限性？

*   **与顶级闭源模型的差距：** 尽管它在很多榜单上超过了 GPT-3.5，但在处理极其复杂的逻辑推理和架构设计时，距离 **GPT-4** 仍有一段距离（如 LeetCode 的 Hard 题目）。

*   **长文本的极致表现：** 虽然支持 16K 并宣称能扩展到 64K，但论文也提到，在极长上下文下，模型的注意力和准确度仍有待进一步优化。

*   **微调数据的依赖：** 指令版本（Instruct model）非常依赖高质量的人类指令数据，如果微调数据不够多样化，模型处理玄学需求的能力会受限。

***

### 6. 关键架构图/流程图解读

这篇论文中有几张图对理解非常有帮助：

*   **图 1 (The Performance)：** 展示了一个雷达图。你会看到 DeepSeek-Coder 在 Python、C++、Java 等多个维度上形成了一个“大圆”，包围了其他开源模型，直观展示了其全能性。右侧的 LeetCode 柱状图显示它大幅领先 GPT-3.5。

*   **图 2 (Dataset Creation)：** 这是一个流程图，描述了从抓取 GitHub 数据到规则过滤、**依赖解析（Dependency Parsing）**、再到去重的全过程。它告诉我们：高质量的代码模型不是随便喂点数据就行，关键在于复杂的清洗和逻辑重组。

*   **算法 1 (Topological Sort for Dependency Analysis)：** 这是论文的技术灵魂。它展示了如何通过算法计算文件之间的依赖。**它的作用是：** 确保模型在学习时，能像人类看代码库一样，先看“底层基础”，再看“上层建筑”，从而真正理解项目结构。

*   **图 3 (Effectiveness of FIM)：** 展示了不同 FIM 比例对模型能力的影响曲线，解释了为什么开发团队最终选择了目前的训练策略。

### 总结给学生：

你可以把 DeepSeek-Coder 想象成一个\*\*“读过全 GitHub 项目的超级实习生”\*\*。以前的 AI 实习生只是在背代码片段，而 DeepSeek-Coder 是在理解“整个项目是怎么串起来的”，并且它不仅会写新作业，还会熟练地在你写了一半的程序里填空。

## 思考一

1.  解释一下如何通过算法计算文件之间的依赖？
2.  训练过程中是如何利用这个依赖关系的？比如是把依赖关系作为训练的输入数据之一吗？
3.  解释一下FIM策略是什么？

***

非常好，这三个问题切中了 DeepSeek-Coder 论文中最核心的“工程细节”。作为研究员，我最喜欢这种深挖技术原理的问题。

我们一个一个来拆解：

***

### 1. 如何通过算法计算文件之间的依赖？

在处理一个项目（Repository）时，模型如果不了解文件间的逻辑，它看到的只是散落的零件。论文通过 **Algorithm 1（拓扑排序）** 把这些零件串成了有意义的流水线。

**具体步骤如下：**

1.  **特征提取（解析）：**

    *   系统会扫描项目中的每个文件，利用“正则表达式”去寻找特定编程语言的关键字。

    *   比如：在 Python 里找 `import`，在 C# 里找 `using`，在 C 语言里找 `#include`。

    *   **结论：** 如果文件 A 里面写了 `import B`，算法就记录下一条逻辑：**A 依赖于 B**。

2.  **构建图论模型：**

    *   算法会建立一个“有向图”。在这个图里，每个文件是一个点，如果 A 依赖 B，就画一条从 B 指向 A 的箭头。
    *   这里引入了一个概念叫\*\*“入度” (In-degree)\*\*：如果一个文件被很多其他文件引用，它的入度就高；如果没有文件引用它，它的入度就是 0。

3.  **排序算法（拓扑排序）：**

    *   通常的拓扑排序是找入度为 0 的点（即不依赖任何人的基础文件）排在最前面。

    *   **论文的改进：** 现实代码中存在“循环引用”（A 调 B，B 又调 A）。标准的算法遇到这种情况会卡死。DeepSeek 团队改用了\*\*“最小入度”策略\*\*：即使没有入度为 0 的点，也选入度最小的点开始排，从而强行处理掉循环依赖，得出一个全局的先后顺序。

***

### 2. 训练过程中是如何利用这个依赖关系的？

这是一个非常好的误区识别点。**依赖关系并不是作为一种“结构化数据”（比如图形或表格）直接输入给模型的。**

**它的真正用途是：决定数据“喂”给模型的顺序。**

*   **传统做法：** 把项目里的文件 A, B, C 随便排个序，拼接在一起塞给模型。当模型读到 A 里的某个函数调用时，它可能还没读过 B，所以它一脸懵逼，不知道这个函数是干嘛的。

*   **DeepSeek 的做法：** 根据刚才算出的依赖顺序，把文件重新排列。

    *   比如排序结果是 B -> A -> C。

    *   在训练时，模型看到的输入序列是：`[文件B的内容] + [文件A的内容] + [文件C的内容]`。

    *   **关键点：** 当模型预测到文件 A 的代码时，文件 B 的内容已经在它的“上下文窗口”（Context Window）里了。

    *   **效果：** 这模拟了人类看代码的逻辑——你总是先看库文件（被调用者），再看业务逻辑（调用者）。这样模型就学会了：**“哦，原来 A 调用的这个变量是在前面的 B 文件里定义的。”** 这极大地提升了模型处理复杂跨文件逻辑的能力。

***

### 3. 解释一下 FIM（Fill-In-Middle）策略是什么？

**FIM** 全称是 **Fill-In-Middle（中间填空）**。这是代码大模型之所以能像 IDE（编程软件）那样实时补全代码的核心秘密。

#### 为什么需要它？

一般的语言模型是“左向右”工作的。给它“1, 2, 3”，它猜“4”。 但在写代码时，场景往往是这样的：

```
def calculate_area(radius):
    import math
    return _________ * (radius ** 2)  # 这里需要填空
```

此时，模型不仅知道\*\*前面（Prefix）**有 radius，还知道**后面（Suffix）\*\*有平方运算。如果只靠“从左往右”猜，它利用不到后面的信息。

#### FIM 是怎么做的？

在训练时，研究员会对代码文件做一个“变魔术”的处理：

1.  **切割：** 把一段完整的代码切成三部分：**前缀 (Prefix)**、**中间 (Middle)**、**后缀 (Suffix)**。

2.  **重组：** 把顺序打乱，拼成一个新的序列：

    *   格式：`<FIM_Prefix> 前缀内容 <FIM_Suffix> 后缀内容 <FIM_Middle>`

    *   后面跟着的就是：**真实的中间内容**。

3.  **训练目标：** 强迫模型在读完“前缀”和“后缀”后，去预测那个被挖掉的“中间”内容。

#### 论文中的细节：

*   **哨兵标记：** 你在 OCR 结果里看到的 `<｜fim_start｜>`、`<｜fim_hole｜>` 就是用来告诉模型：“注意，我要开始考你填空题了！”

*   **比例选择：** 论文通过实验发现，如果 100% 都用这种填空题训练，模型会变傻（失去从头写代码的灵性）。所以他们最终采取了 **50% 的比例**：一半时间让模型练习“从左往右写”，一半时间练习“中间填空”。

**总结一下：**

*   **拓扑排序**是为了让模型有\*\*“全局观”\*\*（懂跨文件逻辑）；

*   **FIM 策略**是为了让模型有\*\*“局部灵活性”\*\*（能在代码任意位置精准补全）。

这两个技术结合起来，才造就了 DeepSeek-Coder 强大的编程能力。理解了吗？
