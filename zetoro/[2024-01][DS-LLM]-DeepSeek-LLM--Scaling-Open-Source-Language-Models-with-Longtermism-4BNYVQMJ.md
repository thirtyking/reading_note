---
tags: []
parent: '[DS-LLM] DeepSeek LLM: Scaling Open-Source Language Models with Longtermism'
collections:
    - 扩展定律
$version: 2278
$libraryID: 1
$itemKey: 4BNYVQMJ

---
\[2024-01]\[DS-LLM] DeepSeek LLM: Scaling Open-Source Language Models with Longtermism

# \[DS-LLM] DeepSeek LLM: Scaling Open-Source Language Models with Longtermism

## 概述

你好！很高兴能为你解读这篇名为《DeepSeek LLM: Scaling Open-Source Language Models with Longtermism》（DeepSeek LLM：以长期主义规模化开源语言模型）的论文。

DeepSeek 是目前 AI 领域非常受关注的团队，这篇论文详细介绍了他们是如何从底层规律出发，构建出 7B（70亿参数）和 67B（670亿参数）这两个强大模型的过程。

***

### 1. 本论文要解决什么问题？为什么很重要？

**核心问题：** 训练大模型不仅费钱，而且像开盲盒。在有限的预算下，**到底模型该做多大？数据该喂多少？训练参数（如学习率、Batch Size）该怎么设？** 这些控制模型生长的“配方”被称为 **Scaling Laws（缩放定律）**。

**重要性：**

*   **省钱省力：** 训练一个 67B 模型需要消耗巨大的算力资源。如果 Scaling Laws 找错了，可能费了半天劲训练出来的模型效果还不如规模更小的模型。

*   **开源界的基准：** 之前的缩放定律研究（如 OpenAI 的 Kaplan 定律或 DeepMind 的 Chinchilla 定律）结论并不完全一致。DeepSeek 想要为开源社区提供一套更准确、经过大规模验证的“训练手册”。

### 2. 难点在哪里？之前的方案为什么不够好？

**难点：**

*   **预测的不确定性：** 在小模型上观察到的规律，在大模型上未必成立。

*   **超参数难调：** 学习率（LR）和批大小（Batch Size）对效果影响巨大，但在大模型上直接实验太贵了。

**之前方案的问题：**

1.  **参数评估不准：** 以前的研究通常只看“模型参数量（ $N$ ）”，但这忽略了计算过程中的一些固定开销（比如 Attention 机制的计算量）。论文指出，在小模型上，这种误差可能高达 50%。

2.  **忽视了数据质量：** 以前的定律大多假设数据质量是恒定的，但实际上，数据越好，Scaling Laws 的表现也会随之改变。

3.  **学习率策略僵硬：** 业界常用的 Cosine（余弦）学习率调度器虽然效果好，但它有个致命缺点：必须提前定好训练多少步。如果你中途想增加数据再多训会儿，效果就会打折扣。

### 3. 本论文提出了何种解决方案？

DeepSeek 采取了“先摸清规律，再按方抓药”的思路：

1.  **重新定义“尺子”：** 他们引入了 **$M$（每个 Token 的非嵌入计算量 FLOPs）** 来代替传统的参数量  $N$ 。这把尺子更精准，能把 Attention 等计算开销也算进去，从而在预测大模型表现时误差更小。

2.  **推导超参数公式：** 通过大量小规模实验，他们拟合出了两个核心公式（见论文第 9 页公式 1），可以直接算出在特定算力预算下，最合适的 Batch Size 和学习率是多少。

3.  **长期主义的数据处理：**

    *   **极致去重：** 论文展示了在 91 个 Common Crawl 数据集上进行大规模跨库去重，去重率接近 90%。

    *   **数据质量决定模型大小：** 他们发现了一个重要规律：**数据质量越高，增加算力时就越应该优先把模型做大，而不是简单地堆数据量。**

4.  **多步学习率调度（Multi-step LR）：** 放弃了 Cosine 调度，改用分段下降的策略。这样模型在训练完 2 万亿 Token 后，如果还想继续训练，可以直接接着训，而不需要推倒重来。

### 4. 方案的核心创新点在哪里？

*   **数据质量对 Scaling Laws 的修正：** 这是这篇论文非常有价值的发现。它告诉我们，如果你手里的是“精排”的高质量数据，那就大胆把模型参数量堆上去，回报率更高。

*   **深而窄的架构：** 相比于 Llama 等模型，DeepSeek 67B 设计得更“深”（95层），通过增加深度而不是宽度来提升推理和表达能力。

*   **大规模中文语料的融合：** 建立了包含 2 万亿 Token 的中英文双语数据集，在中文能力上不仅超越了 Llama 2，在逻辑、代码、数学等硬核领域表现尤为突出。

### 5. 本方案有什么局限性？

1.  **多语言覆盖尚窄：** 虽然中英文极强，但对于其他小语种的覆盖还在起步阶段。

2.  **幻觉与时效性：** 像所有 LLM 一样，它依然存在知识幻觉（一本正经胡说八道）的问题，且知识截止日期是 2023 年 5 月。

3.  **小模型的语言冲突：** 论文提到，7B 这样的小模型在同时处理中英文时，存在明显的“语言冲突”，导致其在某些垂直任务上的表现上限受限。

***

### 6. 关键图表解读（辅助理解）

*   **Figure 1 (Page 6): 学习率曲线对比**

    *   **内容：** 展示了 Multi-step 调度和 Cosine 调度的训练损耗曲线。

    *   **理解：** 它证明了 Multi-step 虽然在中间阶段看起来损耗略高，但最终能达到和 Cosine 相当的效果，且赋予了模型“持续学习”的灵活性。

*   **Figure 3 (Page 9): 超参数缩放曲线**

    *   **内容：** 展示了 Batch Size 随算力增加而上升，学习率随算力增加而下降的趋势。

    *   **理解：** 这就是 DeepSeek 的“导航地图”，让研究员在训练千亿模型前就能预知最合适的训练配置。

*   **Table 2 (Page 5): 模型规格表**

    *   **内容：** 列出了 7B 和 67B 的层数、维度、头数等。

    *   **理解：** 注意 67B 的 `kv_heads` 只有 8 个（采用了 GQA 技术），这说明模型在追求性能的同时，非常注重推理时的内存效率。

*   **Figure 4 & 5 (Page 11): IsoFLOP 曲线（山谷图）**

    *   **内容：** 图中有很多 U 型曲线，最低点代表在给定算力下最完美的模型/数据比例。

    *   **理解：** 这是 Scaling Laws 的核心体现。它直观地展示了随着算力（不同颜色的线）增加，最优解是如何向更大的模型规模移动的。

**总结：** DeepSeek 这篇论文就像是一份大模型训练的“避坑指南”。它告诉学生们：训练 AI 不只是艺术，更是精密计算的科学。通过更准的度量衡（$M$）和对数据质量的深刻洞察，我们可以更科学地走向通用人工智能（AGI）。

## 思考一

1.  业界常用的 Cosine（余弦）学习率调度器是什么？为什么如果你中途想增加数据再多训会儿，效果就会打折扣？
2.  为什么多步学习率调度的分段下降的策略可以解决上面的问题？

***

这是一个非常深入且专业的问题，触及了大模型训练中一个非常关键的“工程陷阱”。为了让你理解透彻，我们先用一个形象的比喻，再进入技术细节。

***

### 1. 业界常用的 Cosine（余弦）学习率调度器是什么？

**余弦调度器（Cosine Scheduler）** 的核心思想是让学习率随时间遵循一条余弦曲线：

*   **初期：** 学习率很快从一个很小的值升到最高（Warm-up）。

*   **中期到后期：** 逐渐下降，曲线在开始下降时比较平缓，中间变陡，最后在接近训练结束时再次变平缓，直到降低到一个接近 0 的极小值。

**为什么它效果好？** 它符合人类学习的直觉：刚开始接触新知识要“大步快走”（高学习率），快速建立认知框架；最后阶段要“小心微调”（极低学习率），在细节上精益求精。目前 Llama 等大多数主流模型都默认使用这种方式，因为它在**预先设定的步数内**通常能达到最低的损耗（Loss）。

#### 为什么中途想增加数据，效果就会打折扣？

余弦调度器最大的问题在于它的\*\*“deadline（截稿日期）”依赖症\*\*。

*   **数学逻辑：** 在计算余弦公式时，必须输入一个参数  $T_{max}$ （即总训练步数）。公式会根据这个总步数来决定每一时刻下降的斜率。

*   **“降落伞”困境：** 想象你在跳伞，余弦调度器就像一个自动降落装置。它会根据离地高度（总步数）自动调节降落伞。

    *   如果你原本计划在 1000 米降落，降落伞会在 100 米时收紧，让你平稳落地。

    *   **意外发生：** 当你降落到 10 米、马上要落地（学习率几乎为 0）时，老板突然说：“数据又多了 1 万亿，咱们再飞 5000 米吧！”

    *   **后果：** 此时你的学习率已经降到几乎为 0，模型已经“凝固”了，不再吸收新知识。如果你强行把学习率调高重新训练，模型的参数会受到剧烈冲击，导致训练不稳定（Loss 飙升），甚至让模型“忘掉”之前学好的精细特征。

**一句话总结：余弦调度器是一种“一次性”的训练计划，一旦定好了终点，中途很难更改。**

***

### 2. 为什么多步学习率调度（Multi-step）可以解决这个问题？

DeepSeek 采用的 **多步调度（Multi-step / Step Decay）** 不再是一条平滑的余弦曲线，而是像**下台阶**一样：

1.  **长时间的“高原期”：** 在训练的前 80% 时间里，保持一个较高的学习率（或者极其缓慢的下降）。

2.  **断崖式下降：** 到了特定的里程碑（如 80% 处），学习率突然降到一个较低的水平（比如除以 10）。

3.  **最后的平滑期：** 在最后阶段再进行微调。

#### 它为什么能解决“中途加餐”的问题？

我们可以用\*\*“飞机的巡航与降落”\*\*来对比：

*   **余弦调度是“匀速降落”：** 只要起飞，就一直在为降落做准备。一旦想多飞一会儿，由于你已经进入降落航道且速度太慢，很难再拉起来。

*   **多步调度是“高空巡航 + 快速降落”：**

    *   **灵活性：** 只要还没到那个“降落台阶”，飞机就一直在高空巡航速度（高学习率）飞行。

    *   **可重用性（核心优点）：** 如果 DeepSeek 训练了 2 万亿 Token 发现效果很好，想训练到 3 万亿。由于前 80% 的“巡航阶段”学习率是稳定的，他们可以直接把这 2 万亿的训练进度当作一个“存档点”，直接从这里往后接着训练，而不需要重新计算降落曲线。

    *   **逻辑：** 因为在巡航期，模型并没有进入“微调收敛”状态，它依然保持着很强的探索和吸收能力。

**DeepSeek 的创新实验（Figure 1b）：** 论文中提到，他们尝试了不同的分段比例（比如 60% 降、70% 降或 80% 降）。他们发现，虽然降落点不同，但在同一算力预算下，最终模型的表现和余弦调度器几乎一样好，甚至在某些情况下更优。

### 总结

*   **Cosine** 就像是\*\*“破釜沉舟”\*\*，计划性极强，但没有退路，适合预算极其明确的任务。

*   **Multi-step** 则是\*\*“长期主义”\*\*，它把训练看作一个可以随时延长、随时追加投资的过程。这非常符合 DeepSeek 论文标题中的 **Longtermism（长期主义）** —— 既然模型要不断迭代、不断吸收新数据，那么训练策略就必须留有余地，而不是在第一天就把终点锁死。
