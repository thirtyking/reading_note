---
tags: []
parent: '[YaRN] YaRN: Efficient Context Window Extension of Large Language Models'
collections:
    - 核心组件
$version: 2251
$libraryID: 1
$itemKey: W4VILBN4

---
\[2023-09]\[YaRN] YaRN: Efficient Context Window Extension of Large Language Models

# \[YaRN] YaRN: Efficient Context Window Extension of Large Language Models

## 概述

你好！很高兴看到你开始关注大模型上下文扩展（Context Window Extension）这个领域。这是目前 LLM（大语言模型）应用中最“痛”的点之一。

这篇论文 **YaRN (Yet another RoPE for N-times context window)** 虽然名字听起来很随意（YaRN 在英文里也有“纱线”或“故事”的意思），但它其实是 LLaMA 等现代开源模型能够支持几十 K 甚至上百 K 上下文长度的关键技术之一。

来，我们把这篇论文拆解一下，用你能听懂的语言聊聊它到底干了什么。

***

### 1. 这篇论文要解决什么问题？为什么它很重要？

**问题：** 简单说，就是\*\*“如何让大模型由于‘近视’变成‘千里眼’，而且还得省钱省力”\*\*。

大多数开源模型（比如 LLaMA 2）在训练时，上下文窗口（Context Window，即模型一次能处理的最大文本长度）是固定的，比如 4096 个 token。如果你硬要把 1 万字的小说塞进去，超出了它的训练范围，模型就会彻底“懵圈”，输出乱码或胡言乱语。

**重要性：** 现在的应用场景对“长记忆”需求太大了：

*   **读长文档：** 丢给模型一份 50 页的财报让它总结。
*   **写代码：** 让模型理解整个项目的代码库，而不是只看当前文件。
*   **长对话：** 聊天机器人聊了半小时后，不能忘记最开始你叫什么名字。

如果不能低成本地扩展上下文，这些应用都跑不通。

***

### 2. 解决这个问题的难点在哪里？之前的方案为何不够好？

<a href="./[2021-04][RoPE]-RoFormer--Enhanced-Transformer-with-Rotary-Position-Embedding-D3S8URW6.md" rel="noopener noreferrer nofollow" zhref="zotero://note/u/D3S8URW6/" ztype="znotelink" class="internal-link">[2021-04][RoPE] RoFormer: Enhanced Transformer with Rotary Position Embedding</a>

**核心难点：位置编码（Positional Encoding）。** 目前的模型大都使用 **RoPE（旋转位置编码）**。你可以把它想象成给每个词打上一个“坐标”。模型训练时只见过 0 到 4096 范围内的坐标。当你突然给它一个 5000 的坐标，这种\*\*外推（Extrapolation）\*\*会让模型无法适应，因为它从未学过如何处理这么大的数字。

**之前的解决方案及缺陷：**

1.  **直接微调（Fine-tuning）：**

    *   *做法：* 强行用长文本重新训练模型。
    *   *缺点：* **太贵太慢！** 计算资源消耗极大。

2.  **线性插值（Linear Interpolation, PI）：**

    *   *做法：* 想象一把刻度尺（0-4096）。现在你要量更长的物体，但不想造新尺子。于是你把“刻度”压缩了。原来 1 格代表 1 米，现在 1 格代表 2 米。这样就能用旧尺子量更长的距离。
    *   *缺点：* **“分辨率”下降。** 当你压缩了刻度，模型就分不清相邻两个词的顺序了（本来距离是 1，压缩后变得很小，模型觉得它们重叠了）。这导致模型虽然能读长文，但理解能力（尤其是对局部细节的关注）变差。

3.  **NTK-aware 插值（Neural Tangent Kernel-aware）：**

    *   *做法：* 这是 YaRN 的前身。它发现 RoPE 的不同维度（Dimension）对位置信息的敏感度不同。它尝试通过数学技巧，只压缩那些“变化慢”的维度，保留“变化快”的维度。
    *   *缺点：* 虽然比线性插值好，但它**无法完美兼顾**“原来的短文本能力”和“新的长文本能力”。在扩展倍数很大时（比如扩展 10 倍），模型会迷失方向。

***

### 3. YaRN 提出了什么解决方案？为什么能行？

YaRN 的核心思路是：**精细化操作，分而治之，外加注意力修正。**

它主要做了三件事来解决上述问题：

**第一步：NTK-by-parts（分段 NTK 插值）** RoPE 的数学原理涉及不同频率的正弦/余弦函数。YaRN 发现：

*   **高频维度（High Frequency）：** 变化很快，负责捕捉**局部信息**（比如“我”后面紧跟“吃”）。这部分信息对距离非常敏感，**绝对不能压缩（插值）**，否则会打乱词序。
*   **低频维度（Low Frequency）：** 变化很慢，负责捕捉**全局信息**（比如文章开头的“张三”和结尾的“他”）。这部分信息需要**进行插值**，才能让模型理解更远的距离。

**YaRN 的做法：** 它可以把维度分成三组：完全不插值的、稍微插一点的、完全插值的。这种“混合打法”既保留了局部词序的清晰度，又扩展了全局视野。

**第二步：Attention Scaling（注意力缩放）** 当上下文变长时，注意力机制（Attention Mechanism）中的“点积”数值分布会发生变化，导致模型关注的焦点变得“发散”（Entropy 增加，即熵增）。就像你看得东西太多，眼神就涣散了。 **YaRN 的做法：** 乘上一个**温度系数（Temperature Scaling）**。简单说，就是通过数学手段强行把模型的注意力“聚焦”回来，让它在长上下文中依然保持敏锐。

***

### 4. 方案的核心创新点在哪里？

1.  **针对不同频率维度的“差异化对待”：** 之前的方案要么全压缩，要么按统一规则压缩。YaRN 明确提出：**高频维度不能动（Extrapolation），低频维度必须动（Interpolation）。** 这种混合策略完美平衡了局部理解和长程关联。
2.  **即插即用且极其高效：** YaRN 证明了，你只需要用**极少量**的长文本数据（大约是原训练量的 0.1%）进行微调，就能让模型完美适应新的长度。如果不微调，直接用 YaRN 也能跑（虽然微调一下效果最好）。
3.  **解决了“注意力熵增”问题：** 通过引入温度系数修正注意力分布，这是之前单纯修改位置编码的方法所忽略的。

***

### 5. 局限性与劣势

虽然 YaRN 很强，但也不是完美的：

1.  **还是需要微调（Fine-tuning）：** 虽然它号称不用微调也能跑（Zero-shot），但为了达到最佳效果，通常还是建议进行少量的微调。如果不微调，性能虽然比直接硬推好，但会有所下降。
2.  **实现复杂度略增：** 相比于最简单的线性插值（只改一行代码），YaRN 需要修改计算 RoPE 的逻辑，代码实现稍微复杂一点点（当然现在主流库如 HuggingFace Transformers 已经集成了）。
3.  **并非无限扩展：** YaRN 解决了位置编码的问题，但上下文长度最终还是受限于**显存（VRAM）**。把窗口开到 128k，你的显卡可能先爆了，这需要配合 Flash Attention 等其他显存优化技术一起使用。

### 总结给学生

你可以把 **YaRN** 理解为给大模型配的一副**“多焦段眼镜”**：

*   **老方案（线性插值）** 是把眼镜度数调低，看得远了但看近处（局部细节）模糊了。
*   **YaRN** 则是镜片上方看远（低频插值），下方看近（高频保持），并且还加了一层滤镜（温度缩放）防止用眼疲劳。这使得它成为目前开源社区扩展 LLaMA 上下文最主流、最高效的方法之一。

## 思考一

1.  线性插值具体是怎么做的？是说在训练时窗口是4096，推理时把实际距离为N的两个词的位置按N/2进行处理吗？
2.  RoPE自身不是就具备外推性的吗，为什么在这里又会说"模型训练时只见过 0 到 4096 范围内的坐标。当你突然给它一个 5000 的坐标，这种\*\*外推（Extrapolation）\*\*会让模型无法适应，因为它从未学过如何处理这么大的数字"
3.  解释一下NTK-aware插值是怎么做的？这里提到的"RoPE 的不同维度（Dimension）对位置信息的敏感度不同"是什么意思？什么是高频维度，什么是低频维度？
4.  注意力缩放是什么意思？是指在attention时要求注意力只能聚焦在少数词上吗？如何做到的？
5.  用YaRN做微调具体怎么调？不微调，直接用YaRN跑，具体又是怎么跑？

***

学生你好，这五个问题提得非常专业！说明你不仅听懂了大概，还在尝试把新知识和脑子里已有的概念（比如 RoPE 的外推性、Attention 机制）做链接。

这五个问题其实触及了大模型底层数学直觉的核心。别担心，我逐一拆解给你看，保证你豁然开朗。

***

### 1. 线性插值具体是怎么做的？

**你的理解基本正确，但表述上需要更严谨一点。**

*   **做法：** 并不是直接把“距离”除以 2，而是把**“绝对位置索引（Position Index）”**进行缩放。

*   **举例：**

    *   假设模型训练长度是  $L=4096$ 。

    *   现在你想把窗口扩展到 8192（扩大 2 倍，即  $Scale=2$ ）。

    *   当推理时，来了一个词，它的真实位置是第 8000 位。

    *   **线性插值（Linear Interpolation）会欺骗模型**：它告诉模型，“兄弟，你别慌，这个词的位置其实是  $8000 / 2 = 4000$ ”。

    *   于是，模型就调用它在训练中学过的“第 4000 号位置”的编码来处理这个词。

**后果：** 所有的相对距离也被压缩了。原来两个词挨着（距离 1），现在模型看来它们距离只有 0.5。这就导致了“分辨率降低”，模型对局部词序的判断变模糊。

***

### 2. RoPE 自身不是就具备外推性吗？为什么还需要插值？

**这是一个非常经典的误区。理论上 RoPE 可以外推，但实际上模型“学废了”。**

*   **理论上：** RoPE 的数学公式确实对任何  $N$  (位置) 都有定义，不管  $N$  是 5000 还是 10000，公式都能算出一个向量。

*   **实际上（OOD 问题）：** 神经网络是一个统计模型，它非常依赖**数据分布**。

    *   在训练时，模型看到的  $Cos(\theta)$  和  $Sin(\theta)$  的数值变化规律都是基于 0-4096 这个范围的。

    *   当你给它一个 5000 的位置，RoPE 算出来的旋转角度可能是一个模型从未见过的模式，或者在这个角度上，注意力机制（Attention）算出来的分数（Score）会发生异常波动。

    *   **通俗比喻：** 就像你教一个孩子数数，只教了 1 到 100。虽然数学规律可以推到 1000，但当你突然问他“1000 + 1 等于几”，他因为从未见过 3 位数以上的运算，心里会发慌，不仅算不对，甚至可能胡言乱语。

**结论：** RoPE 具备**理论上的**外推性，但神经网络没有学会如何利用这个外推性。所以我们需要用插值法，把新位置“映射”回它熟悉的范围内。

***

### 3. NTK-aware 插值和“高频/低频”维度是怎么回事？

这个问题是 YaRN 的核心，也是最难理解的部分。

**RoPE 的本质：** RoPE 是把向量的维度两两分组，每一组都在旋转。重点来了：**不同维度的旋转速度（频率）是不一样的！**

*   **前面的维度（高频）：** 转得飞快。位置变 1 格，它可能转了 30 度。
*   **后面的维度（低频）：** 转得极慢。位置变 1 格，它可能只转了 0.001 度。

**什么是高频/低频维度？** 想象一个多针的时钟：

*   **秒针（高频）：** 稍微动一点时间（位置），秒针就转很大的角度。它负责告诉模型\*\*“精确的局部位置”\*\*（比如“我”紧挨着“吃”）。
*   **时针（低频）：** 过了很久，时针才动一点点。它负责告诉模型\*\*“大概的全局距离”\*\*（比如“我”在开头，“吃”在结尾）。

**为什么要区别对待？（NTK-aware 的洞察）**

*   **如果你用线性插值（全都除以 2）：**

    *   **低频（时针）：** 没问题。本来转得就慢，再慢一点模型也能接受，看起来差不多。
    *   **高频（秒针）：** 出大事了！秒针本来转得很快，能清晰区分每一秒。你强行让它慢一倍，原本清晰的“滴答滴答”变成了模糊的拖影。模型就分不清相邻两个词谁先谁后了。

**YaRN (NTK-aware) 的做法：**

*   **对低频维度（时针）：** 进行**插值**（压缩）。让它挤一挤，把长文塞进去。
*   **对高频维度（秒针）：** **保持原样（外推）**！不压缩它。因为高频维度具有很强的周期性，模型即使没见过大数字，也能根据它的快速旋转猜出大概。

**一句话总结：** 为了保住局部语序的清晰度，高频部分不许动（或者少动），只折腾那些变化慢的低频部分。

***

### 4. 注意力缩放（Attention Scaling）是什么意思？

**这是为了解决“注意力被稀释”的问题。**

*   **现象：** Softmax 函数有一个特点。当参与计算的项变多时（上下文从 4k 变 100k），所有的概率值都会变得很小且平均。

    *   短文时：关注重点词，概率可能是 0.8，噪音词是 0.01。
    *   长文时：因为候选词太多，重点词概率可能降到了 0.05，噪音词是 0.001。
    *   **结果（熵增）：** 模型的“眼神”变得涣散，不知道该看哪了。

*   **做法：** 在做 Softmax 之前，人为地乘上一个系数（比如 $\sqrt{t}$ ，或者 YaRN 中的温度系数）。 $\text{Attention}(Q, K, V) = \text{Softmax}(\frac{QK^T}{\sqrt{d} \cdot \text{温度系数}}) V$

*   **目的：** 这个系数会让原本大的数值更大，小的数值更小。

    *   **通俗比喻：** 就像调高图片的“对比度”。让模糊的注意力分布重新变得尖锐（Sharp），强迫模型重新聚焦在关键信息上。

***

### 5. 用 YaRN 做微调和不微调怎么跑？

这是一个关于\*\*代码实现（Inference）**和**权重更新（Training）\*\*的区别。

**场景 A：不微调，直接用 YaRN 跑（Zero-shot）**

*   **怎么跑：** 你不需要训练模型。你只需要修改模型加载的代码（比如修改 `config.json` 或推理脚本）。
*   **具体动作：** 告诉模型：“嘿，现在用 YaRN 的公式来计算位置编码，不要用原来的 RoPE 公式。”
*   **结果：** 模型的**权重参数（Weights）完全没变**，但是因为位置编码的计算方式变了（用了混合插值），模型突然就能处理长文了。虽然效果可能不如微调好，但比直接崩溃强得多。

**场景 B：用 YaRN 做微调（Fine-tuning）**

*   **怎么跑：**

    1.  开启 YaRN 模式（修改位置编码计算公式）。
    2.  准备一批长文本数据（比如 64k 长度的文章）。
    3.  把数据喂给模型，计算 Loss，**更新模型的权重参数**。

*   **为什么快？** 论文提到，只需要极少量的步数（几百步）。

*   **目的：** 让模型的权重去“适应”YaRN 这种新的位置编码方式，把那些微小的误差修正过来。这样效果就是 State-of-the-Art（最先进）的了。

***

**总结一下：** YaRN 就像是给大模型换了一副\*\*“特制眼镜”\*\*。

*   **RoPE** 是裸眼。
*   **线性插值** 是近视镜，看远清楚了，但看近处（词序）模糊了。
*   **YaRN** 是**双光眼镜**（高频看近不缩放，低频看远缩放），外加一层**滤光片**（注意力缩放，提高对比度）。
*   **微调** 就是让大脑适应这副新眼镜的过程。

## 思考二

1.  YaRN和NTK-aware插值的差异在哪里？
2.  YaRN的混合插值具体是怎么选择高频维度和低频维度的，以及如何决定每个维度怎么插值的？
3.  Transformer架构里的激活函数不是GELU吗？softmax用在什么地方？和GELU什么关系？

***

这三个问题问得非常精准！这说明你已经开始尝试构建模型内部的“3D 地图”了。

我们继续拆解，把这几个关键概念彻底厘清。

***

### 1. YaRN 和 NTK-aware 插值的本质差异在哪里？

虽然 YaRN 是基于 NTK-aware 发展来的，但它们对待“高频维度”的态度完全不同。

*   **NTK-aware 的策略：全局调整，平滑过渡**

    *   **做法：** 它用一个数学公式，把所有维度的刻度都改了。
    *   **结果：** 高频维度改得少，低频维度改得多。
    *   **问题：** 哪怕改得再少，**高频维度还是被动了**。
    *   **后果：** 就像你调节收音机旋钮，虽然主要想调低音，但高音也被稍微带偏了一点点。对于大模型来说，高频维度的微小变化都会导致对“相邻词序”（Local Positional Information）的判断变差。

*   **YaRN 的策略：分区治理，泾渭分明**

    *   **做法：** YaRN 更加激进且精细。它直接切分了三个区域。

    *   **结果：**

        1.  **高频区：** **完全不动！**（保持原样，纯外推）。
        2.  **低频区：** **大力压缩！**（按倍数线性插值）。
        3.  **中间区：** 平滑过渡。

    *   **优势：** YaRN 完美保留了高频信息。这意味着模型在读长文时，依然能像读短文一样，极度精准地掌握相邻词的关系（比如“人工”和“智能”紧挨着）。

**一句话总结差异：** NTK-aware 是“全部维度都根据频率调一下”；YaRN 是“高频维度**坚决不动**，只调低频，中间搞个过渡”。

***

### 2. YaRN 的混合插值具体怎么选择高频/低频？怎么决定插值力度？

YaRN 引入了一个概念叫\*\*“波长”（Wavelength, $\lambda$）\*\*。 在 RoPE 中，每个维度都对应一个旋转频率，频率越低，波长越长（转一圈需要的距离越长）。

YaRN 设定了两个**阈值（超参数）**，我们姑且称之为 **$A$（短波界限）** 和 **$B$（长波界限）**。

#### **具体的“三段式”操作逻辑：**

1.  **高频区（波长 $\lambda < A$）：**

    *   这些维度转得非常快（比如负责捕捉“的”、“了”这种紧邻关系的）。

    *   **操作：** **不插值**。插值系数  $\alpha = 0$ 。

    *   **含义：** 保持原来的训练时的刻度，让模型利用外推能力。

2.  **低频区（波长 $\lambda > B$）：**

    *   这些维度转得非常慢（比如负责捕捉文章开头和结尾关系的）。

    *   **操作：** **全插值**。插值系数  $\alpha = 1$ 。

    *   **含义：** 如果你要扩展 4 倍窗口，这里的刻度就老老实实压缩 4 倍（即线性插值）。

3.  **中频区（$A \le \lambda \le B$）：**

    *   **操作：** **线性过渡（Ramp）**。

    *   **含义：** 根据波长在  $A$  和  $B$  之间的位置，计算出一个  $0$  到  $1$  之间的系数。波长越接近  $B$ ，插值力度就越大。

#### **如何决定 A 和 B？**

这两个数是 YaRN 论文作者通过实验测出来的经验值（通常与上下文扩展的倍数有关）。在实际代码中（如 `transformers` 库的实现），这些已经是写好的默认参数，用户通常不需要自己手算，除非你要做非常深度的魔改。

***

### 3. Transformer 里的 Softmax 和 GELU 有什么关系？

这是一个非常棒的基础架构问题！这俩都是“非线性函数”，但它们在 Transformer 的“身体”里负责完全不同的器官。

你可以把 Transformer 的每一层想象成一个\*\*“两步走”\*\*的工厂车间：

#### **第一步：注意力机制（Attention）—— Softmax 的地盘**

*   **任务：** 决定“看哪里”。

*   **场景：** 模型在处理单词“苹果”时，需要决定是关注“手机”还是关注“水果”。

*   **过程：**

    1.  计算相关性分数（Score）。

    2.  **使用 Softmax：** 将这些分数归一化为**概率值**（加起来等于 1）。

        *   比如：关注“手机”的概率是 0.9，关注“水果”的概率是 0.1。

*   **为什么是 Softmax？** 因为我们需要一个“竞争机制”，选出最重要的信息，压抑不重要的信息。YaRN 里的“温度缩放（Temperature Scaling）”就是作用在这里，修改进入 Softmax 之前的数值。

#### **第二步：前馈神经网络（FFN / MLP）—— GELU 的地盘**

*   **任务：** 负责“思考和理解”。

*   **场景：** 模型已经拿到了“苹果”和“手机”的信息，现在需要在大脑里加工，提取特征。

*   **过程：**  $Input \to Linear \to \text{GELU} \to Linear \to Output$ 。

*   **为什么是 GELU？**

    *   GELU（Gaussian Error Linear Unit）是一种**激活函数**。
    *   神经元如果不加激活函数，多少层叠加都只是线性变换（矩阵乘法），只有加了激活函数，模型才有处理复杂逻辑（非线性）的能力。
    *   GELU 相比传统的 ReLU，在零点附近更平滑，理论上允许微小的负值通过，在大模型训练中表现更稳定。

#### **总结它们的关系：**

*   **Softmax** 是\*\*“路由器”\*\*：它决定信息流向哪里（权重分配）。
*   **GELU** 是\*\*“处理器”\*\*：它负责把这一层的信息嚼碎、消化、提取特征。

**在 YaRN 这篇论文中：** YaRN 主要修改的是 **RoPE（位置编码）** 和 **Attention 里的 Softmax 计算（温度系数）**。它**完全没有动** FFN 里的 GELU。所以你理解的 GELU 依然在那里工作，只是这篇论文的改动不涉及它。
